{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep2eK29S_5qq"
   },
   "source": [
    "\n",
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90wz8D6UuSs9",
    "outputId": "dd983309-3b41-4363-eec7-483d11cfc237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.5.3\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JlLkEWbmiyYj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5y4nEnfSfbv",
    "outputId": "aad59339-03c4-473b-acae-55777e539d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V1stgVndkEQm"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/content/drive/MyDrive/groups_090.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m catalog \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/groups_090.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/astridenv/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.conda/envs/astridenv/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/content/drive/MyDrive/groups_090.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "catalog = '/content/drive/MyDrive/groups_090.hdf5'\n",
    "f = h5py.File(catalog, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THXTiqZQmCO0"
   },
   "outputs": [],
   "source": [
    "M_star = f['Subhalo/SubhaloMassType'][:,4]*1e10\n",
    "pos  = f['Subhalo/SubhaloPos'][:]/1e3\n",
    "vel = f['Subhalo/SubhaloVel'][:]\n",
    "met = f['Subhalo/SubhaloStarMetallicity'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dgJ7wxu6sLUM"
   },
   "outputs": [],
   "source": [
    "def load_and_filter_data(file, mass_threshold=2e8):\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        positions = f['Subhalo/SubhaloPos'][:]/1e3  # Convert to Mpc/h\n",
    "        vel = f['Subhalo/SubhaloVel'][:]\n",
    "        metallicities = f['Subhalo/SubhaloStarMetallicity'][:]\n",
    "        masses = f['Subhalo/SubhaloMassType'][:,4]*1e10  # Stellar mass\n",
    "        omega_m = f['Header'].attrs['Omega0']\n",
    "\n",
    "    # Filter galaxies based on the stellar mass threshold\n",
    "    mask = masses > mass_threshold\n",
    "    positions = positions[mask]\n",
    "    vel = vel[mask]\n",
    "    metallicities = metallicities[mask]\n",
    "    masses = masses[mask]\n",
    "\n",
    "    return positions, vel, metallicities, masses, omega_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "--oaAn3kDLtU"
   },
   "outputs": [],
   "source": [
    "def apply_periodic_boundary_conditions(positions, box_size):\n",
    "    # Wrap positions to the box size\n",
    "    positions = positions % box_size\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B7VnGquYDPRe"
   },
   "outputs": [],
   "source": [
    "def minimum_image_distance(pos1, pos2, box_size):\n",
    "    # Calculate the minimum image distance between two points\n",
    "    delta = np.abs(pos1 - pos2)\n",
    "    delta = np.where(delta > 0.5 * box_size, box_size - delta, delta)\n",
    "    return np.sqrt((delta ** 2).sum(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lKOyScsvstrg"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def distance(point1, point2):\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def create_edges_knn(points, k=6):\n",
    "    edges = []\n",
    "    edge_value = []\n",
    "\n",
    "    # Create a KDTree for efficient nearest neighbor search\n",
    "    point_tree = KDTree(points)\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        # Query the k nearest neighbors for each point\n",
    "        _, neighbors = point_tree.query(points[i], k=k+1)\n",
    "\n",
    "        for j in neighbors[1:]:  # Skip the first neighbor because it's the point itself\n",
    "            # Add an edge between the point and its neighbor\n",
    "            edges.append([i, j])\n",
    "\n",
    "            # Compute the distance between the points as the edge value\n",
    "            edge_value.append(distance(points[i], points[j]))\n",
    "\n",
    "    return [edges, edge_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ztRfbIqROn7N"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def min_distance(positions, box_size = 25):\n",
    "    min_distance = np.inf\n",
    "    max_distance = 0\n",
    "\n",
    "    # Iterate over all pairs of galaxies\n",
    "    for i in range(len(positions)):\n",
    "        for j in range(i + 1, len(positions)):\n",
    "            dist = minimum_image_distance(positions[i], positions[j], box_size)\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Minimum distance: {min_distance} Mpc/h\")\n",
    "    print(f\"Maximum distance: {max_distance} Mpc/h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l40oy2_KRiWJ"
   },
   "outputs": [],
   "source": [
    "def minimum_image_distance_vectorized(positions, box_size = 25):\n",
    "    num_galaxies = positions.shape[0]\n",
    "\n",
    "    # Compute pairwise differences in each dimension\n",
    "    diff = positions[:, np.newaxis, :] - positions[np.newaxis, :, :]\n",
    "\n",
    "    # Apply periodic boundary conditions\n",
    "    diff = np.abs(diff)\n",
    "    diff = np.where(diff > 0.5 * box_size, box_size - diff, diff)\n",
    "\n",
    "    # Compute the Euclidean distance\n",
    "    dist = np.sqrt(np.sum(diff ** 2, axis=-1))\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zPQB3MDzDcid"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.spatial import cKDTree\n",
    "def create_edges_knn_pbc(points, box_size = 25, k=6):\n",
    "    tree = KDTree(points, boxsize=box_size)\n",
    "\n",
    "    edges = []\n",
    "    edge_values = []\n",
    "    '''\n",
    "    distances = minimum_image_distance_vectorized(points, box_size)\n",
    "    # Mask the diagonal (self-distances which are zero)\n",
    "    np.fill_diagonal(distances, np.inf)\n",
    "    # Get the minimum and maximum distances\n",
    "    min_distance = np.min(distances)\n",
    "    max_distance = np.max(np.triu(distances, k=1))\n",
    "    print(min_distance, max_distance)\n",
    "    '''\n",
    "\n",
    "    min_distance = np.inf\n",
    "    max_distance = 0\n",
    "    large_distance_count = 0\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        distances, neighbors = tree.query(points[i], k=k+1)\n",
    "        for j, tree_dist in zip(neighbors[1:], distances[1:]):\n",
    "            if j != i and j < len(points):\n",
    "                actual_distance = minimum_image_distance(points[i], points[j], box_size)\n",
    "                edges.append([i, j])\n",
    "                edge_values.append(actual_distance)\n",
    "                min_distance = min(min_distance, actual_distance)\n",
    "                max_distance = max(max_distance, actual_distance)\n",
    "    return np.array(edges), np.array(edge_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m5XiGu3wtkRA"
   },
   "outputs": [],
   "source": [
    "def create_points(positions, masses, vel, met):\n",
    "    point_features = []\n",
    "    for i, pos in enumerate(positions):\n",
    "        #point_features.append(list(pos) + list(vel[i]) + [masses[i]] + [met[i]])\n",
    "        point_features.append(list(pos) + [masses[i]] + [met[i]])\n",
    "    return point_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3CE9AtwhuAKs"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "def create_graph(file_path, k_val=6):\n",
    "    positions, velocity, metallicities, masses, omega_m = load_and_filter_data(file_path)\n",
    "    edges, edge_values = create_edges_knn_pbc(positions, 25, k_val)\n",
    "    point_values = create_points(positions, masses, velocity, metallicities)\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    point_values = torch.tensor(point_values, dtype=torch.float)\n",
    "    edge_value = torch.tensor(edge_values, dtype=torch.float)\n",
    "\n",
    "    return [point_values, edge_index, edge_value, omega_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mhxwN1mIub7M"
   },
   "outputs": [],
   "source": [
    "def turn_data(graph):\n",
    "    graph_data = Data(x=graph[0], edge_index=graph[1], edge_attr=graph[2], y = graph[3])\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_PXmi7cFLFqy"
   },
   "outputs": [],
   "source": [
    "def create_data(file_path, k_val=6):\n",
    "    graph = create_graph(file_path, k_val)\n",
    "    return turn_data(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLywIItfwd0D",
    "outputId": "dd6d8298-ff3b-4420-ed46-1ba990f8a354"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/content/drive/MyDrive/groups_090.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/groups_090.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m, in \u001b[0;36mcreate_data\u001b[0;34m(file_path, k_val)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_data\u001b[39m(file_path, k_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m turn_data(graph)\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mcreate_graph\u001b[0;34m(file_path, k_val)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_graph\u001b[39m(file_path, k_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     positions, velocity, metallicities, masses, omega_m \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_filter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     edges, edge_values \u001b[38;5;241m=\u001b[39m create_edges_knn_pbc(positions, \u001b[38;5;241m25\u001b[39m, k_val)\n\u001b[1;32m      6\u001b[0m     point_values \u001b[38;5;241m=\u001b[39m create_points(positions, masses, velocity, metallicities)\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36mload_and_filter_data\u001b[0;34m(file, mass_threshold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_filter_data\u001b[39m(file, mass_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e8\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m         positions \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubhalo/SubhaloPos\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e3\u001b[39m  \u001b[38;5;66;03m# Convert to Mpc/h\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         vel \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubhalo/SubhaloVel\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n",
      "File \u001b[0;32m~/.conda/envs/astridenv/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.conda/envs/astridenv/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/content/drive/MyDrive/groups_090.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "create_data('/content/drive/MyDrive/groups_090.hdf5', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V9zLYGSy_cz4"
   },
   "outputs": [],
   "source": [
    "def calculate_normalization_params(data_list):\n",
    "    # Concatenate all node features and edge attributes\n",
    "    all_x = torch.cat([data.x for data in data_list], dim=0)\n",
    "    all_edge_attr = torch.cat([data.edge_attr for data in data_list], dim=0)\n",
    "\n",
    "    # Calculate mean and std for node features and edge attributes\n",
    "    x_mean, x_std = all_x.mean(dim=0), all_x.std(dim=0)\n",
    "    edge_attr_mean, edge_attr_std = all_edge_attr.mean(dim=0), all_edge_attr.std(dim=0)\n",
    "\n",
    "    return (x_mean, x_std), (edge_attr_mean, edge_attr_std)\n",
    "\n",
    "def normalize_dataset(data_list, x_params, edge_attr_params):\n",
    "    x_mean, x_std = x_params\n",
    "    edge_attr_mean, edge_attr_std = edge_attr_params\n",
    "\n",
    "    normalized_data_list = []\n",
    "    for data in data_list:\n",
    "        normalized_x = (data.x - x_mean) / (x_std + 1e-8)\n",
    "        normalized_edge_attr = (data.edge_attr - edge_attr_mean) / (edge_attr_std + 1e-8)\n",
    "\n",
    "        # Create a new Data object with normalized features and original y value\n",
    "        normalized_data = Data(x=normalized_x,\n",
    "                               edge_index=data.edge_index,\n",
    "                               edge_attr=normalized_edge_attr,\n",
    "                               y=data.y)  # Preserve the original y value\n",
    "\n",
    "        normalized_data_list.append(normalized_data)\n",
    "\n",
    "    return normalized_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qoAJQ_raMZ3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:19<00:00,  5.01it/s]\n",
      "/home/hk4638/.conda/envs/astridenv/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "import h5py\n",
    "directory = '/scratch/gpfs/hk4638/FinalData/NewData'\n",
    "def load_all_graphs(directory, k_val=10, box_size=25):\n",
    "    file_list = os.listdir(directory)\n",
    "    data_list = []\n",
    "    for file_name in tqdm(file_list):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        graph_data = create_data(file_path, k_val)\n",
    "        data_list.append(graph_data)\n",
    "    return data_list\n",
    "\n",
    "# Load all graphs\n",
    "data_list = load_all_graphs(directory)\n",
    "\n",
    "# Calculate normalization parameters based on all graphs\n",
    "x_params, edge_attr_params = calculate_normalization_params(data_list)\n",
    "\n",
    "# Normalize the dataset using the calculated parameters\n",
    "normalized_data_list = normalize_dataset(data_list, x_params, edge_attr_params)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def numpy_to_torch_float(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return torch.from_numpy(data).float()\n",
    "    elif isinstance(data, (np.float64, np.float32)):\n",
    "        return torch.tensor(data, dtype=torch.float32)\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.float()\n",
    "    else:\n",
    "        return data\n",
    "        \n",
    "def ensure_torch_float32(data):\n",
    "    data.x = numpy_to_torch_float(data.x)\n",
    "    data.edge_attr = numpy_to_torch_float(data.edge_attr)\n",
    "    if hasattr(data, 'y'):\n",
    "        data.y = numpy_to_torch_float(data.y)\n",
    "    return data\n",
    "    \n",
    "normalized_data_list = [ensure_torch_float32(data) for data in normalized_data_list]\n",
    "\n",
    "# Calculate the lengths for the 70-15-15 split\n",
    "total_len = len(normalized_data_list)\n",
    "train_len = int(0.7 * total_len)\n",
    "val_len = int(0.15 * total_len)\n",
    "test_len = total_len - train_len - val_len  # Ensures all data is used\n",
    "\n",
    "# Perform the split\n",
    "train_data, val_data, test_data = random_split(normalized_data_list, [train_len, val_len, test_len])\n",
    "\n",
    "# Create DataLoaders for each split\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eD3eA9nTAAch"
   },
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mksges42ACLq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "class ComplexGAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers=4, heads=4, dropout_rate=0.1):\n",
    "        super(ComplexGAT, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, concat=True, edge_dim=1)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            GATConv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, edge_dim=1)\n",
    "            for _ in range(num_layers - 2)\n",
    "        ])\n",
    "\n",
    "        self.conv_last = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=False, edge_dim=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, 1)  # Output a single value for omega_m\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr=edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index, edge_attr=edge_attr))\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        x = self.conv_last(x, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_5UGNXhNAggG"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, num_epochs=100, lr=0.001, load_best_model=False):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if load_best_model:\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('/home/hk4638/ondemand/data/sys/AstridLH/best_model.pth'))\n",
    "            print(\"Loaded model from best_model.pth\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"best_model.pth not found. Starting with a new model.\")\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_mses = []\n",
    "    val_r2s = []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            epoch_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            for data in epoch_pbar:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = criterion(out, data.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                epoch_pbar.set_postfix({'Train Loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_predictions = []\n",
    "            val_true = []\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    data = data.to(device)\n",
    "                    out = model(data)\n",
    "                    val_loss += criterion(out, data.y).item()\n",
    "                    val_predictions.extend(out.cpu().numpy())\n",
    "                    val_true.extend(data.y.cpu().numpy())\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            val_mse = mean_squared_error(val_true, val_predictions)\n",
    "            val_r2 = r2_score(val_true, val_predictions)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            val_mses.append(val_mse)\n",
    "            val_r2s.append(val_r2)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "            print(f'  Train Loss: {train_loss:.4f}')\n",
    "            print(f'  Val Loss: {val_loss:.4f}')\n",
    "            print(f'  Val MSE: {val_mse:.4f}')\n",
    "            print(f'  Val R2: {val_r2:.4f}')\n",
    "            \n",
    "            # Save the model after each epoch\n",
    "            torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
    "            print(f'  Model saved as model_epoch_{epoch+1}.pth')\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model.state_dict()\n",
    "                torch.save(best_model, 'best_model.pth')\n",
    "                print('  New best model saved as best_model.pth!')\n",
    "            \n",
    "            print()  # Add an empty line for better readability between epochs\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted. Saving current model state...\")\n",
    "        torch.save(model.state_dict(), 'interrupted_model.pth')\n",
    "        print(\"Model saved as interrupted_model.pth\")\n",
    "        if best_model is not None:\n",
    "            model.load_state_dict(best_model)\n",
    "        return model, train_losses, val_losses, val_mses, val_r2s\n",
    "    \n",
    "    # Load the best model if training completed without interruption\n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "    \n",
    "    return model, train_losses, val_losses, val_mses, val_r2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mxL3nt4Avrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0058\n",
      "  Val MSE: 0.0058\n",
      "  Val R2: 0.5759\n",
      "  Model saved as model_epoch_1.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200:\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0054\n",
      "  Val MSE: 0.0053\n",
      "  Val R2: 0.6092\n",
      "  Model saved as model_epoch_2.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200:\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0061\n",
      "  Val MSE: 0.0060\n",
      "  Val R2: 0.5556\n",
      "  Model saved as model_epoch_3.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200:\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0063\n",
      "  Val MSE: 0.0062\n",
      "  Val R2: 0.5441\n",
      "  Model saved as model_epoch_4.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200:\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0056\n",
      "  Val MSE: 0.0055\n",
      "  Val R2: 0.5920\n",
      "  Model saved as model_epoch_5.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200:\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0062\n",
      "  Val MSE: 0.0061\n",
      "  Val R2: 0.5517\n",
      "  Model saved as model_epoch_6.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200:\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0071\n",
      "  Val MSE: 0.0071\n",
      "  Val R2: 0.4803\n",
      "  Model saved as model_epoch_7.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200:\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0055\n",
      "  Val MSE: 0.0054\n",
      "  Val R2: 0.6003\n",
      "  Model saved as model_epoch_8.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200:\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0071\n",
      "  Val MSE: 0.0070\n",
      "  Val R2: 0.4815\n",
      "  Model saved as model_epoch_9.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200:\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0059\n",
      "  Val MSE: 0.0058\n",
      "  Val R2: 0.5753\n",
      "  Model saved as model_epoch_10.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200:\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0060\n",
      "  Val MSE: 0.0059\n",
      "  Val R2: 0.5643\n",
      "  Model saved as model_epoch_11.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200:\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0067\n",
      "  Val MSE: 0.0066\n",
      "  Val R2: 0.5108\n",
      "  Model saved as model_epoch_12.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200:\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0057\n",
      "  Val MSE: 0.0056\n",
      "  Val R2: 0.5879\n",
      "  Model saved as model_epoch_13.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200:\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0060\n",
      "  Val MSE: 0.0059\n",
      "  Val R2: 0.5659\n",
      "  Model saved as model_epoch_14.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200:\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0064\n",
      "  Val MSE: 0.0063\n",
      "  Val R2: 0.5355\n",
      "  Model saved as model_epoch_15.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200:\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0064\n",
      "  Val MSE: 0.0063\n",
      "  Val R2: 0.5393\n",
      "  Model saved as model_epoch_16.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200:\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0070\n",
      "  Val MSE: 0.0069\n",
      "  Val R2: 0.4901\n",
      "  Model saved as model_epoch_17.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200:\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0063\n",
      "  Val MSE: 0.0062\n",
      "  Val R2: 0.5452\n",
      "  Model saved as model_epoch_18.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200:\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0061\n",
      "  Val MSE: 0.0060\n",
      "  Val R2: 0.5564\n",
      "  Model saved as model_epoch_19.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200:\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0060\n",
      "  Val MSE: 0.0059\n",
      "  Val R2: 0.5645\n",
      "  Model saved as model_epoch_20.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200:\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0063\n",
      "  Val MSE: 0.0063\n",
      "  Val R2: 0.5388\n",
      "  Model saved as model_epoch_21.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200:\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0063\n",
      "  Val MSE: 0.0062\n",
      "  Val R2: 0.5404\n",
      "  Model saved as model_epoch_22.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200:\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0077\n",
      "  Val MSE: 0.0077\n",
      "  Val R2: 0.4357\n",
      "  Model saved as model_epoch_23.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200:\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0071\n",
      "  Val MSE: 0.0071\n",
      "  Val R2: 0.4804\n",
      "  Model saved as model_epoch_24.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200:\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0067\n",
      "  Val MSE: 0.0066\n",
      "  Val R2: 0.5124\n",
      "  Model saved as model_epoch_25.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 100%|██████████| 22/22 [01:02<00:00,  2.84s/it, Train Loss=0.0049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200:\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0074\n",
      "  Val MSE: 0.0073\n",
      "  Val R2: 0.4600\n",
      "  Model saved as model_epoch_26.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200:\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0066\n",
      "  Val MSE: 0.0065\n",
      "  Val R2: 0.5202\n",
      "  Model saved as model_epoch_27.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200:\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0073\n",
      "  Val MSE: 0.0072\n",
      "  Val R2: 0.4691\n",
      "  Model saved as model_epoch_28.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200:\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0075\n",
      "  Val MSE: 0.0075\n",
      "  Val R2: 0.4465\n",
      "  Model saved as model_epoch_29.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200:\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0068\n",
      "  Val MSE: 0.0067\n",
      "  Val R2: 0.5066\n",
      "  Model saved as model_epoch_30.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200:\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0077\n",
      "  Val MSE: 0.0077\n",
      "  Val R2: 0.4332\n",
      "  Model saved as model_epoch_31.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200:\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0081\n",
      "  Val MSE: 0.0081\n",
      "  Val R2: 0.4061\n",
      "  Model saved as model_epoch_32.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200:\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0079\n",
      "  Val MSE: 0.0078\n",
      "  Val R2: 0.4221\n",
      "  Model saved as model_epoch_33.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200:\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0076\n",
      "  Val MSE: 0.0076\n",
      "  Val R2: 0.4429\n",
      "  Model saved as model_epoch_34.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200:\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0085\n",
      "  Val MSE: 0.0084\n",
      "  Val R2: 0.3802\n",
      "  Model saved as model_epoch_35.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200:\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0090\n",
      "  Val MSE: 0.0090\n",
      "  Val R2: 0.3386\n",
      "  Model saved as model_epoch_36.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200:\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0062\n",
      "  Val MSE: 0.0061\n",
      "  Val R2: 0.5542\n",
      "  Model saved as model_epoch_37.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200:\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0076\n",
      "  Val MSE: 0.0075\n",
      "  Val R2: 0.4464\n",
      "  Model saved as model_epoch_38.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200:\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0063\n",
      "  Val MSE: 0.0062\n",
      "  Val R2: 0.5416\n",
      "  Model saved as model_epoch_39.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200: 100%|██████████| 22/22 [01:02<00:00,  2.85s/it, Train Loss=0.0046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200:\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0074\n",
      "  Val MSE: 0.0074\n",
      "  Val R2: 0.4575\n",
      "  Model saved as model_epoch_40.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200:\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0069\n",
      "  Val MSE: 0.0068\n",
      "  Val R2: 0.4959\n",
      "  Model saved as model_epoch_41.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200:\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0076\n",
      "  Val MSE: 0.0076\n",
      "  Val R2: 0.4408\n",
      "  Model saved as model_epoch_42.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200:\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0072\n",
      "  Val MSE: 0.0072\n",
      "  Val R2: 0.4725\n",
      "  Model saved as model_epoch_43.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200: 100%|██████████| 22/22 [01:02<00:00,  2.86s/it, Train Loss=0.0024]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize model\n",
    "in_channels = normalized_data_list[0].num_node_features\n",
    "hidden_channels = 128\n",
    "num_layers = 3\n",
    "heads = 4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "model = ComplexGAT(in_channels, hidden_channels, num_layers, heads, dropout_rate)\n",
    "\n",
    "# Train model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = train_model(model, train_loader, val_loader, device, num_epochs = 200, lr=0.001, load_best_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class Objective(object):\n",
    "    def __init__(self, num_features, device, epochs, train_loader, val_loader):\n",
    "        self.num_features = num_features\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.best_trial_number = None\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        # Define the directory for saving files\n",
    "        save_dir = '/scratch/gpfs/hk4638/astrid_optimization'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Names of the files that will contain the losses, model weights, and hyperparameters\n",
    "        fout = os.path.join(save_dir, f'loss_{trial.number}.txt')\n",
    "        fmodel = os.path.join(save_dir, f'model_{trial.number}.pth')\n",
    "        fhyper = os.path.join(save_dir, f'hyperparameters_{trial.number}.json')\n",
    "\n",
    "        # Suggest hyperparameters\n",
    "        hidden_channels = trial.suggest_categorical('hidden_channels', [64, 128, 256])\n",
    "        num_layers = trial.suggest_int('num_layers', 2, 6)\n",
    "        heads = trial.suggest_categorical('heads', [4, 8, 16])\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "        lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "\n",
    "        # Save hyperparameters to a JSON file\n",
    "        hyperparameters = {\n",
    "            'hidden_channels': hidden_channels,\n",
    "            'num_layers': num_layers,\n",
    "            'heads': heads,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'lr': lr\n",
    "        }\n",
    "        with open(fhyper, 'w') as f:\n",
    "            json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "        # Generate the model architecture\n",
    "        model = ComplexGAT(in_channels=self.num_features, hidden_channels=hidden_channels,\n",
    "                           num_layers=num_layers, heads=heads,\n",
    "                           dropout_rate=dropout_rate).to(self.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "    \n",
    "        def train():\n",
    "            model.train()\n",
    "            train_bar = tqdm(self.train_loader, leave=False, desc=f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "            for data in train_bar:\n",
    "                data = data.to(self.device)\n",
    "                out = model(data)\n",
    "                loss = criterion(out.squeeze(), data.y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        def validate(loader):\n",
    "            model.eval()\n",
    "            total_loss = 0\n",
    "            num_batches = 0\n",
    "            with torch.no_grad():\n",
    "                for data in loader:\n",
    "                    data = data.to(self.device)\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out.squeeze(), data.y)\n",
    "                    total_loss += loss.item()\n",
    "                    num_batches += 1\n",
    "            return total_loss / num_batches\n",
    "\n",
    "        # Train and validate model\n",
    "        trial_best_val_loss = float('inf')\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            train()\n",
    "            val_loss = validate(self.val_loader)\n",
    "            \n",
    "            if val_loss < trial_best_val_loss:\n",
    "                trial_best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), fmodel)\n",
    "            \n",
    "            with open(fout, 'a') as f:\n",
    "                f.write(f'{epoch} {val_loss:.5e} {trial_best_val_loss:.5e}\\n')\n",
    "\n",
    "            # Handle pruning based on the intermediate value\n",
    "            trial.report(val_loss, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        # Update best overall model if this trial is the best so far\n",
    "        if trial_best_val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = trial_best_val_loss\n",
    "            self.best_trial_number = trial.number\n",
    "\n",
    "            # Save the best trial number immediately\n",
    "            with open(os.path.join(save_dir, 'best_trial.json'), 'w') as f:\n",
    "                json.dump({\n",
    "                    'best_trial_number': self.best_trial_number,\n",
    "                    'best_val_loss': self.best_val_loss\n",
    "                }, f, indent=4)\n",
    "\n",
    "        # Print trial results\n",
    "        print(f\"\\n--- Trial {trial.number} Results ---\")\n",
    "        print(\"Hyperparameters:\")\n",
    "        for key, value in trial.params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(f\"\\nCurrent Model Architecture:\\n{model}\")\n",
    "        print(f\"\\nBest Validation Loss for this trial: {trial_best_val_loss:.5e}\")\n",
    "        print(f\"Best Overall Validation Loss: {self.best_val_loss:.5e} (Trial {self.best_trial_number})\")\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return trial_best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-16 00:23:15,857] A new study created in RDB with name: astrid_gnn_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new study 'astrid_gnn_optimization'\n",
      "Running 50 additional trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Epoch 1/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1/10:   5%|▍         | 1/22 [00:02<00:53,  2.54s/it]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 2/22 [00:04<00:45,  2.26s/it]\u001b[A\n",
      "Epoch 1/10:  14%|█▎        | 3/22 [00:07<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 4/22 [00:08<00:34,  1.91s/it]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 5/22 [00:10<00:32,  1.91s/it]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 6/22 [00:12<00:33,  2.07s/it]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 7/22 [00:15<00:32,  2.19s/it]\u001b[A\n",
      "Epoch 1/10:  36%|███▋      | 8/22 [00:16<00:28,  2.07s/it]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 9/22 [00:18<00:25,  1.93s/it]\u001b[A\n",
      "Epoch 1/10:  45%|████▌     | 10/22 [00:20<00:22,  1.90s/it]\u001b[A\n",
      "Epoch 1/10:  50%|█████     | 11/22 [00:22<00:20,  1.86s/it]\u001b[A\n",
      "Epoch 1/10:  55%|█████▍    | 12/22 [00:24<00:19,  1.92s/it]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 13/22 [00:26<00:17,  1.97s/it]\u001b[A\n",
      "Epoch 1/10:  64%|██████▎   | 14/22 [00:28<00:16,  2.03s/it]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 15/22 [00:30<00:13,  1.95s/it]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 16/22 [00:31<00:11,  1.84s/it]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 17/22 [00:33<00:09,  1.85s/it]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 18/22 [00:35<00:07,  1.86s/it]\u001b[A\n",
      "Epoch 1/10:  86%|████████▋ | 19/22 [00:37<00:05,  2.00s/it]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 20/22 [00:39<00:04,  2.01s/it]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▌| 21/22 [00:41<00:02,  2.05s/it]\u001b[A\n",
      "Epoch 1/10: 100%|██████████| 22/22 [00:43<00:00,  1.99s/it]\u001b[A\n",
      " 10%|█         | 1/10 [00:48<07:13, 48.17s/it]             \u001b[A\n",
      "Epoch 2/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2/10:   5%|▍         | 1/22 [00:01<00:35,  1.70s/it]\u001b[A\n",
      "Epoch 2/10:   9%|▉         | 2/22 [00:04<00:43,  2.20s/it]\u001b[A\n",
      "Epoch 2/10:  14%|█▎        | 3/22 [00:06<00:40,  2.11s/it]\u001b[A\n",
      "Epoch 2/10:  18%|█▊        | 4/22 [00:07<00:35,  1.96s/it]\u001b[A\n",
      "Epoch 2/10:  23%|██▎       | 5/22 [00:10<00:34,  2.05s/it]\u001b[A\n",
      "Epoch 2/10:  27%|██▋       | 6/22 [00:12<00:34,  2.16s/it]\u001b[A\n",
      "Epoch 2/10:  32%|███▏      | 7/22 [00:14<00:31,  2.10s/it]\u001b[A\n",
      "Epoch 2/10:  36%|███▋      | 8/22 [00:16<00:30,  2.15s/it]\u001b[A\n",
      "Epoch 2/10:  41%|████      | 9/22 [00:19<00:29,  2.29s/it]\u001b[A\n",
      "Epoch 2/10:  45%|████▌     | 10/22 [00:20<00:24,  2.01s/it]\u001b[A\n",
      "Epoch 2/10:  50%|█████     | 11/22 [00:22<00:21,  1.93s/it]\u001b[A\n",
      "Epoch 2/10:  55%|█████▍    | 12/22 [00:24<00:18,  1.86s/it]\u001b[A\n",
      "Epoch 2/10:  59%|█████▉    | 13/22 [00:26<00:18,  2.08s/it]\u001b[A\n",
      "Epoch 2/10:  64%|██████▎   | 14/22 [00:28<00:15,  1.92s/it]\u001b[A\n",
      "Epoch 2/10:  68%|██████▊   | 15/22 [00:30<00:13,  1.90s/it]\u001b[A\n",
      "Epoch 2/10:  73%|███████▎  | 16/22 [00:31<00:10,  1.78s/it]\u001b[A\n",
      "Epoch 2/10:  77%|███████▋  | 17/22 [00:33<00:09,  1.82s/it]\u001b[A\n",
      "Epoch 2/10:  82%|████████▏ | 18/22 [00:35<00:07,  1.87s/it]\u001b[A\n",
      "Epoch 2/10:  86%|████████▋ | 19/22 [00:37<00:05,  1.84s/it]\u001b[A\n",
      "Epoch 2/10:  91%|█████████ | 20/22 [00:39<00:03,  1.79s/it]\u001b[A\n",
      "Epoch 2/10:  95%|█████████▌| 21/22 [00:42<00:02,  2.18s/it]\u001b[A\n",
      "Epoch 2/10: 100%|██████████| 22/22 [00:43<00:00,  2.03s/it]\u001b[A\n",
      " 20%|██        | 2/10 [01:36<06:24, 48.08s/it]             \u001b[A\n",
      "Epoch 3/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3/10:   5%|▍         | 1/22 [00:02<00:45,  2.19s/it]\u001b[A\n",
      "Epoch 3/10:   9%|▉         | 2/22 [00:04<00:39,  2.00s/it]\u001b[A\n",
      "Epoch 3/10:  14%|█▎        | 3/22 [00:05<00:35,  1.88s/it]\u001b[A\n",
      "Epoch 3/10:  18%|█▊        | 4/22 [00:08<00:37,  2.11s/it]\u001b[A\n",
      "Epoch 3/10:  23%|██▎       | 5/22 [00:10<00:34,  2.04s/it]\u001b[A\n",
      "Epoch 3/10:  27%|██▋       | 6/22 [00:11<00:30,  1.89s/it]\u001b[A\n",
      "Epoch 3/10:  32%|███▏      | 7/22 [00:13<00:26,  1.74s/it]\u001b[A\n",
      "Epoch 3/10:  36%|███▋      | 8/22 [00:15<00:25,  1.82s/it]\u001b[A\n",
      "Epoch 3/10:  41%|████      | 9/22 [00:17<00:23,  1.84s/it]\u001b[A\n",
      "Epoch 3/10:  45%|████▌     | 10/22 [00:20<00:27,  2.29s/it]\u001b[A\n",
      "Epoch 3/10:  50%|█████     | 11/22 [00:22<00:23,  2.14s/it]\u001b[A\n",
      "Epoch 3/10:  55%|█████▍    | 12/22 [00:24<00:20,  2.05s/it]\u001b[A\n",
      "Epoch 3/10:  59%|█████▉    | 13/22 [00:26<00:19,  2.13s/it]\u001b[A\n",
      "Epoch 3/10:  64%|██████▎   | 14/22 [00:28<00:17,  2.21s/it]\u001b[A\n",
      "Epoch 3/10:  68%|██████▊   | 15/22 [00:30<00:14,  2.14s/it]\u001b[A\n",
      "Epoch 3/10:  73%|███████▎  | 16/22 [00:32<00:12,  2.05s/it]\u001b[A\n",
      "Epoch 3/10:  77%|███████▋  | 17/22 [00:34<00:10,  2.01s/it]\u001b[A\n",
      "Epoch 3/10:  82%|████████▏ | 18/22 [00:36<00:08,  2.05s/it]\u001b[A\n",
      "Epoch 3/10:  86%|████████▋ | 19/22 [00:38<00:06,  2.10s/it]\u001b[A\n",
      "Epoch 3/10:  91%|█████████ | 20/22 [00:40<00:03,  1.96s/it]\u001b[A\n",
      "Epoch 3/10:  95%|█████████▌| 21/22 [00:42<00:01,  1.89s/it]\u001b[A\n",
      "Epoch 3/10: 100%|██████████| 22/22 [00:43<00:00,  1.86s/it]\u001b[A\n",
      " 30%|███       | 3/10 [02:24<05:37, 48.17s/it]             \u001b[A\n",
      "Epoch 4/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4/10:   5%|▍         | 1/22 [00:02<00:55,  2.63s/it]\u001b[A\n",
      "Epoch 4/10:   9%|▉         | 2/22 [00:04<00:41,  2.07s/it]\u001b[A\n",
      "Epoch 4/10:  14%|█▎        | 3/22 [00:06<00:36,  1.94s/it]\u001b[A\n",
      "Epoch 4/10:  18%|█▊        | 4/22 [00:08<00:34,  1.93s/it]\u001b[A\n",
      "Epoch 4/10:  23%|██▎       | 5/22 [00:09<00:32,  1.89s/it]\u001b[A\n",
      "Epoch 4/10:  27%|██▋       | 6/22 [00:11<00:31,  1.94s/it]\u001b[A\n",
      "Epoch 4/10:  32%|███▏      | 7/22 [00:14<00:30,  2.02s/it]\u001b[A\n",
      "Epoch 4/10:  36%|███▋      | 8/22 [00:16<00:29,  2.12s/it]\u001b[A\n",
      "Epoch 4/10:  41%|████      | 9/22 [00:18<00:26,  2.02s/it]\u001b[A\n",
      "Epoch 4/10:  45%|████▌     | 10/22 [00:19<00:21,  1.83s/it]\u001b[A\n",
      "Epoch 4/10:  50%|█████     | 11/22 [00:21<00:20,  1.84s/it]\u001b[A\n",
      "Epoch 4/10:  55%|█████▍    | 12/22 [00:24<00:21,  2.14s/it]\u001b[A\n",
      "Epoch 4/10:  59%|█████▉    | 13/22 [00:26<00:18,  2.03s/it]\u001b[A\n",
      "Epoch 4/10:  64%|██████▎   | 14/22 [00:27<00:15,  1.96s/it]\u001b[A\n",
      "Epoch 4/10:  68%|██████▊   | 15/22 [00:30<00:14,  2.10s/it]\u001b[A\n",
      "Epoch 4/10:  73%|███████▎  | 16/22 [00:32<00:12,  2.15s/it]\u001b[A\n",
      "Epoch 4/10:  77%|███████▋  | 17/22 [00:34<00:10,  2.06s/it]\u001b[A\n",
      "Epoch 4/10:  82%|████████▏ | 18/22 [00:36<00:08,  2.02s/it]\u001b[A\n",
      "Epoch 4/10:  86%|████████▋ | 19/22 [00:38<00:06,  2.10s/it]\u001b[A\n",
      "Epoch 4/10:  91%|█████████ | 20/22 [00:40<00:03,  2.00s/it]\u001b[A\n",
      "Epoch 4/10:  95%|█████████▌| 21/22 [00:41<00:01,  1.86s/it]\u001b[A\n",
      "Epoch 4/10: 100%|██████████| 22/22 [00:43<00:00,  1.83s/it]\u001b[A\n",
      " 40%|████      | 4/10 [03:12<04:48, 48.11s/it]             \u001b[A\n",
      "Epoch 5/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5/10:   5%|▍         | 1/22 [00:02<00:49,  2.34s/it]\u001b[A\n",
      "Epoch 5/10:   9%|▉         | 2/22 [00:04<00:47,  2.38s/it]\u001b[A\n",
      "Epoch 5/10:  14%|█▎        | 3/22 [00:07<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 5/10:  18%|█▊        | 4/22 [00:08<00:33,  1.85s/it]\u001b[A\n",
      "Epoch 5/10:  23%|██▎       | 5/22 [00:10<00:33,  1.97s/it]\u001b[A\n",
      "Epoch 5/10:  27%|██▋       | 6/22 [00:12<00:31,  1.96s/it]\u001b[A\n",
      "Epoch 5/10:  32%|███▏      | 7/22 [00:14<00:30,  2.03s/it]\u001b[A\n",
      "Epoch 5/10:  36%|███▋      | 8/22 [00:16<00:26,  1.93s/it]\u001b[A\n",
      "Epoch 5/10:  41%|████      | 9/22 [00:18<00:25,  1.96s/it]\u001b[A\n",
      "Epoch 5/10:  45%|████▌     | 10/22 [00:20<00:23,  1.98s/it]\u001b[A\n",
      "Epoch 5/10:  50%|█████     | 11/22 [00:22<00:21,  1.96s/it]\u001b[A\n",
      "Epoch 5/10:  55%|█████▍    | 12/22 [00:24<00:19,  1.94s/it]\u001b[A\n",
      "Epoch 5/10:  59%|█████▉    | 13/22 [00:25<00:17,  1.93s/it]\u001b[A\n",
      "Epoch 5/10:  64%|██████▎   | 14/22 [00:27<00:15,  1.89s/it]\u001b[A\n",
      "Epoch 5/10:  68%|██████▊   | 15/22 [00:29<00:13,  1.90s/it]\u001b[A\n",
      "Epoch 5/10:  73%|███████▎  | 16/22 [00:31<00:11,  1.87s/it]\u001b[A\n",
      "Epoch 5/10:  77%|███████▋  | 17/22 [00:33<00:09,  1.87s/it]\u001b[A\n",
      "Epoch 5/10:  82%|████████▏ | 18/22 [00:35<00:07,  1.87s/it]\u001b[A\n",
      "Epoch 5/10:  86%|████████▋ | 19/22 [00:36<00:05,  1.84s/it]\u001b[A\n",
      "Epoch 5/10:  91%|█████████ | 20/22 [00:39<00:04,  2.02s/it]\u001b[A\n",
      "Epoch 5/10:  95%|█████████▌| 21/22 [00:42<00:02,  2.25s/it]\u001b[A\n",
      "Epoch 5/10: 100%|██████████| 22/22 [00:43<00:00,  2.08s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [04:00<04:00, 48.15s/it]             \u001b[A\n",
      "Epoch 6/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6/10:   5%|▍         | 1/22 [00:01<00:38,  1.84s/it]\u001b[A\n",
      "Epoch 6/10:   9%|▉         | 2/22 [00:03<00:39,  1.95s/it]\u001b[A\n",
      "Epoch 6/10:  14%|█▎        | 3/22 [00:05<00:32,  1.73s/it]\u001b[A\n",
      "Epoch 6/10:  18%|█▊        | 4/22 [00:07<00:34,  1.91s/it]\u001b[A\n",
      "Epoch 6/10:  23%|██▎       | 5/22 [00:09<00:32,  1.94s/it]\u001b[A\n",
      "Epoch 6/10:  27%|██▋       | 6/22 [00:12<00:35,  2.20s/it]\u001b[A\n",
      "Epoch 6/10:  32%|███▏      | 7/22 [00:14<00:31,  2.08s/it]\u001b[A\n",
      "Epoch 6/10:  36%|███▋      | 8/22 [00:15<00:26,  1.91s/it]\u001b[A\n",
      "Epoch 6/10:  41%|████      | 9/22 [00:17<00:25,  1.96s/it]\u001b[A\n",
      "Epoch 6/10:  45%|████▌     | 10/22 [00:19<00:23,  1.97s/it]\u001b[A\n",
      "Epoch 6/10:  50%|█████     | 11/22 [00:22<00:23,  2.16s/it]\u001b[A\n",
      "Epoch 6/10:  55%|█████▍    | 12/22 [00:23<00:20,  2.02s/it]\u001b[A\n",
      "Epoch 6/10:  59%|█████▉    | 13/22 [00:25<00:18,  2.01s/it]\u001b[A\n",
      "Epoch 6/10:  64%|██████▎   | 14/22 [00:27<00:15,  1.97s/it]\u001b[A\n",
      "Epoch 6/10:  68%|██████▊   | 15/22 [00:29<00:13,  1.92s/it]\u001b[A\n",
      "Epoch 6/10:  73%|███████▎  | 16/22 [00:31<00:11,  1.84s/it]\u001b[A\n",
      "Epoch 6/10:  77%|███████▋  | 17/22 [00:33<00:09,  1.97s/it]\u001b[A\n",
      "Epoch 6/10:  82%|████████▏ | 18/22 [00:35<00:07,  1.96s/it]\u001b[A\n",
      "Epoch 6/10:  86%|████████▋ | 19/22 [00:37<00:06,  2.06s/it]\u001b[A\n",
      "Epoch 6/10:  91%|█████████ | 20/22 [00:39<00:04,  2.02s/it]\u001b[A\n",
      "Epoch 6/10:  95%|█████████▌| 21/22 [00:41<00:01,  1.94s/it]\u001b[A\n",
      "Epoch 6/10: 100%|██████████| 22/22 [00:43<00:00,  2.06s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [04:48<03:12, 48.16s/it]             \u001b[A\n",
      "Epoch 7/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7/10:   5%|▍         | 1/22 [00:02<00:48,  2.33s/it]\u001b[A\n",
      "Epoch 7/10:   9%|▉         | 2/22 [00:03<00:38,  1.91s/it]\u001b[A\n",
      "Epoch 7/10:  14%|█▎        | 3/22 [00:05<00:36,  1.91s/it]\u001b[A\n",
      "Epoch 7/10:  18%|█▊        | 4/22 [00:08<00:39,  2.20s/it]\u001b[A\n",
      "Epoch 7/10:  23%|██▎       | 5/22 [00:10<00:33,  1.98s/it]\u001b[A\n",
      "Epoch 7/10:  27%|██▋       | 6/22 [00:12<00:32,  2.01s/it]\u001b[A\n",
      "Epoch 7/10:  32%|███▏      | 7/22 [00:13<00:28,  1.89s/it]\u001b[A\n",
      "Epoch 7/10:  36%|███▋      | 8/22 [00:15<00:27,  1.93s/it]\u001b[A\n",
      "Epoch 7/10:  41%|████      | 9/22 [00:17<00:24,  1.86s/it]\u001b[A\n",
      "Epoch 7/10:  45%|████▌     | 10/22 [00:19<00:23,  1.93s/it]\u001b[A\n",
      "Epoch 7/10:  50%|█████     | 11/22 [00:21<00:22,  2.05s/it]\u001b[A\n",
      "Epoch 7/10:  55%|█████▍    | 12/22 [00:24<00:20,  2.07s/it]\u001b[A\n",
      "Epoch 7/10:  59%|█████▉    | 13/22 [00:25<00:17,  1.92s/it]\u001b[A\n",
      "Epoch 7/10:  64%|██████▎   | 14/22 [00:28<00:16,  2.10s/it]\u001b[A\n",
      "Epoch 7/10:  68%|██████▊   | 15/22 [00:30<00:15,  2.21s/it]\u001b[A\n",
      "Epoch 7/10:  73%|███████▎  | 16/22 [00:32<00:11,  1.97s/it]\u001b[A\n",
      "Epoch 7/10:  77%|███████▋  | 17/22 [00:34<00:09,  2.00s/it]\u001b[A\n",
      "Epoch 7/10:  82%|████████▏ | 18/22 [00:36<00:08,  2.09s/it]\u001b[A\n",
      "Epoch 7/10:  86%|████████▋ | 19/22 [00:38<00:06,  2.07s/it]\u001b[A\n",
      "Epoch 7/10:  91%|█████████ | 20/22 [00:40<00:04,  2.08s/it]\u001b[A\n",
      "Epoch 7/10:  95%|█████████▌| 21/22 [00:42<00:01,  1.95s/it]\u001b[A\n",
      "Epoch 7/10: 100%|██████████| 22/22 [00:43<00:00,  1.84s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [05:36<02:24, 48.14s/it]             \u001b[A\n",
      "Epoch 8/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8/10:   5%|▍         | 1/22 [00:01<00:40,  1.94s/it]\u001b[A\n",
      "Epoch 8/10:   9%|▉         | 2/22 [00:04<00:46,  2.30s/it]\u001b[A\n",
      "Epoch 8/10:  14%|█▎        | 3/22 [00:06<00:42,  2.23s/it]\u001b[A\n",
      "Epoch 8/10:  18%|█▊        | 4/22 [00:08<00:36,  2.02s/it]\u001b[A\n",
      "Epoch 8/10:  23%|██▎       | 5/22 [00:10<00:34,  2.02s/it]\u001b[A\n",
      "Epoch 8/10:  27%|██▋       | 6/22 [00:13<00:36,  2.26s/it]\u001b[A\n",
      "Epoch 8/10:  32%|███▏      | 7/22 [00:14<00:30,  2.03s/it]\u001b[A\n",
      "Epoch 8/10:  36%|███▋      | 8/22 [00:16<00:28,  2.05s/it]\u001b[A\n",
      "Epoch 8/10:  41%|████      | 9/22 [00:18<00:26,  2.06s/it]\u001b[A\n",
      "Epoch 8/10:  45%|████▌     | 10/22 [00:20<00:23,  1.99s/it]\u001b[A\n",
      "Epoch 8/10:  50%|█████     | 11/22 [00:22<00:21,  1.99s/it]\u001b[A\n",
      "Epoch 8/10:  55%|█████▍    | 12/22 [00:24<00:19,  1.94s/it]\u001b[A\n",
      "Epoch 8/10:  59%|█████▉    | 13/22 [00:27<00:20,  2.23s/it]\u001b[A\n",
      "Epoch 8/10:  64%|██████▎   | 14/22 [00:28<00:15,  1.97s/it]\u001b[A\n",
      "Epoch 8/10:  68%|██████▊   | 15/22 [00:31<00:14,  2.07s/it]\u001b[A\n",
      "Epoch 8/10:  73%|███████▎  | 16/22 [00:33<00:13,  2.20s/it]\u001b[A\n",
      "Epoch 8/10:  77%|███████▋  | 17/22 [00:35<00:10,  2.12s/it]\u001b[A\n",
      "Epoch 8/10:  82%|████████▏ | 18/22 [00:36<00:07,  1.92s/it]\u001b[A\n",
      "Epoch 8/10:  86%|████████▋ | 19/22 [00:38<00:05,  1.84s/it]\u001b[A\n",
      "Epoch 8/10:  91%|█████████ | 20/22 [00:39<00:03,  1.70s/it]\u001b[A\n",
      "Epoch 8/10:  95%|█████████▌| 21/22 [00:42<00:01,  1.91s/it]\u001b[A\n",
      "Epoch 8/10: 100%|██████████| 22/22 [00:43<00:00,  1.79s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [06:25<01:36, 48.16s/it]             \u001b[A\n",
      "Epoch 9/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9/10:   5%|▍         | 1/22 [00:01<00:36,  1.73s/it]\u001b[A\n",
      "Epoch 9/10:   9%|▉         | 2/22 [00:03<00:36,  1.81s/it]\u001b[A\n",
      "Epoch 9/10:  14%|█▎        | 3/22 [00:05<00:30,  1.63s/it]\u001b[A\n",
      "Epoch 9/10:  18%|█▊        | 4/22 [00:07<00:35,  2.00s/it]\u001b[A\n",
      "Epoch 9/10:  23%|██▎       | 5/22 [00:09<00:33,  1.98s/it]\u001b[A\n",
      "Epoch 9/10:  27%|██▋       | 6/22 [00:11<00:30,  1.94s/it]\u001b[A\n",
      "Epoch 9/10:  32%|███▏      | 7/22 [00:13<00:31,  2.07s/it]\u001b[A\n",
      "Epoch 9/10:  36%|███▋      | 8/22 [00:15<00:26,  1.91s/it]\u001b[A\n",
      "Epoch 9/10:  41%|████      | 9/22 [00:17<00:24,  1.86s/it]\u001b[A\n",
      "Epoch 9/10:  45%|████▌     | 10/22 [00:19<00:23,  2.00s/it]\u001b[A\n",
      "Epoch 9/10:  50%|█████     | 11/22 [00:21<00:21,  1.99s/it]\u001b[A\n",
      "Epoch 9/10:  55%|█████▍    | 12/22 [00:22<00:18,  1.90s/it]\u001b[A\n",
      "Epoch 9/10:  59%|█████▉    | 13/22 [00:24<00:17,  1.91s/it]\u001b[A\n",
      "Epoch 9/10:  64%|██████▎   | 14/22 [00:26<00:15,  1.91s/it]\u001b[A\n",
      "Epoch 9/10:  68%|██████▊   | 15/22 [00:29<00:15,  2.19s/it]\u001b[A\n",
      "Epoch 9/10:  73%|███████▎  | 16/22 [00:31<00:12,  2.15s/it]\u001b[A\n",
      "Epoch 9/10:  77%|███████▋  | 17/22 [00:33<00:10,  2.07s/it]\u001b[A\n",
      "Epoch 9/10:  82%|████████▏ | 18/22 [00:35<00:08,  2.15s/it]\u001b[A\n",
      "Epoch 9/10:  86%|████████▋ | 19/22 [00:38<00:06,  2.19s/it]\u001b[A\n",
      "Epoch 9/10:  91%|█████████ | 20/22 [00:39<00:04,  2.02s/it]\u001b[A\n",
      "Epoch 9/10:  95%|█████████▌| 21/22 [00:41<00:02,  2.04s/it]\u001b[A\n",
      "Epoch 9/10: 100%|██████████| 22/22 [00:43<00:00,  1.94s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [07:13<00:48, 48.12s/it]             \u001b[A\n",
      "Epoch 10/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10/10:   5%|▍         | 1/22 [00:01<00:32,  1.54s/it]\u001b[A\n",
      "Epoch 10/10:   9%|▉         | 2/22 [00:04<00:42,  2.12s/it]\u001b[A\n",
      "Epoch 10/10:  14%|█▎        | 3/22 [00:05<00:37,  1.97s/it]\u001b[A\n",
      "Epoch 10/10:  18%|█▊        | 4/22 [00:08<00:37,  2.09s/it]\u001b[A\n",
      "Epoch 10/10:  23%|██▎       | 5/22 [00:10<00:34,  2.02s/it]\u001b[A\n",
      "Epoch 10/10:  27%|██▋       | 6/22 [00:11<00:31,  1.96s/it]\u001b[A\n",
      "Epoch 10/10:  32%|███▏      | 7/22 [00:13<00:29,  1.93s/it]\u001b[A\n",
      "Epoch 10/10:  36%|███▋      | 8/22 [00:15<00:25,  1.85s/it]\u001b[A\n",
      "Epoch 10/10:  41%|████      | 9/22 [00:17<00:25,  1.93s/it]\u001b[A\n",
      "Epoch 10/10:  45%|████▌     | 10/22 [00:19<00:24,  2.02s/it]\u001b[A\n",
      "Epoch 10/10:  50%|█████     | 11/22 [00:21<00:21,  1.94s/it]\u001b[A\n",
      "Epoch 10/10:  55%|█████▍    | 12/22 [00:23<00:19,  1.91s/it]\u001b[A\n",
      "Epoch 10/10:  59%|█████▉    | 13/22 [00:25<00:17,  1.94s/it]\u001b[A\n",
      "Epoch 10/10:  64%|██████▎   | 14/22 [00:27<00:15,  1.89s/it]\u001b[A\n",
      "Epoch 10/10:  68%|██████▊   | 15/22 [00:28<00:12,  1.80s/it]\u001b[A\n",
      "Epoch 10/10:  73%|███████▎  | 16/22 [00:30<00:11,  1.84s/it]\u001b[A\n",
      "Epoch 10/10:  77%|███████▋  | 17/22 [00:33<00:10,  2.03s/it]\u001b[A\n",
      "Epoch 10/10:  82%|████████▏ | 18/22 [00:35<00:08,  2.14s/it]\u001b[A\n",
      "Epoch 10/10:  86%|████████▋ | 19/22 [00:37<00:06,  2.17s/it]\u001b[A\n",
      "Epoch 10/10:  91%|█████████ | 20/22 [00:40<00:04,  2.29s/it]\u001b[A\n",
      "Epoch 10/10:  95%|█████████▌| 21/22 [00:42<00:02,  2.17s/it]\u001b[A\n",
      "Epoch 10/10: 100%|██████████| 22/22 [00:43<00:00,  1.99s/it]\u001b[A\n",
      "100%|██████████| 10/10 [08:01<00:00, 48.14s/it]             \u001b[A\n",
      "[I 2024-08-16 00:31:17,480] Trial 0 finished with value: 0.01637849733233452 and parameters: {'hidden_channels': 64, 'num_layers': 4, 'heads': 4, 'dropout_rate': 0.00034387369884014696, 'lr': 1.9044244634951747e-05}. Best is trial 0 with value: 0.01637849733233452.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 0 Results ---\n",
      "Hyperparameters:\n",
      "  hidden_channels: 64\n",
      "  num_layers: 4\n",
      "  heads: 4\n",
      "  dropout_rate: 0.00034387369884014696\n",
      "  lr: 1.9044244634951747e-05\n",
      "\n",
      "Current Model Architecture:\n",
      "ComplexGAT(\n",
      "  (conv1): GATConv(5, 64, heads=4)\n",
      "  (convs): ModuleList(\n",
      "    (0-1): 2 x GATConv(256, 64, heads=4)\n",
      "  )\n",
      "  (conv_last): GATConv(256, 64, heads=1)\n",
      "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Best Validation Loss for this trial: 1.63785e-02\n",
      "Best Overall Validation Loss: 1.63785e-02 (Trial 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Epoch 1/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1/10:   5%|▍         | 1/22 [00:05<01:51,  5.30s/it]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 2/22 [00:09<01:38,  4.92s/it]\u001b[A\n",
      "Epoch 1/10:  14%|█▎        | 3/22 [00:15<01:38,  5.18s/it]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 4/22 [00:19<01:26,  4.81s/it]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 5/22 [00:25<01:29,  5.28s/it]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 6/22 [00:29<01:15,  4.74s/it]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 7/22 [00:32<01:04,  4.33s/it]\u001b[A\n",
      "Epoch 1/10:  36%|███▋      | 8/22 [00:36<00:58,  4.16s/it]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 9/22 [00:41<00:56,  4.33s/it]\u001b[A\n",
      "Epoch 1/10:  45%|████▌     | 10/22 [00:48<01:01,  5.14s/it]\u001b[A\n",
      "Epoch 1/10:  50%|█████     | 11/22 [00:53<00:56,  5.15s/it]\u001b[A\n",
      "Epoch 1/10:  55%|█████▍    | 12/22 [00:59<00:52,  5.23s/it]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 13/22 [01:03<00:44,  4.92s/it]\u001b[A\n",
      "Epoch 1/10:  64%|██████▎   | 14/22 [01:08<00:41,  5.18s/it]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 15/22 [01:12<00:33,  4.75s/it]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 16/22 [01:17<00:29,  4.87s/it]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 17/22 [01:21<00:23,  4.61s/it]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 18/22 [01:27<00:19,  4.97s/it]\u001b[A\n",
      "Epoch 1/10:  86%|████████▋ | 19/22 [01:32<00:15,  5.01s/it]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 20/22 [01:37<00:09,  4.92s/it]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▌| 21/22 [01:42<00:04,  4.79s/it]\u001b[A\n",
      "Epoch 1/10: 100%|██████████| 22/22 [01:45<00:00,  4.44s/it]\u001b[A\n",
      " 10%|█         | 1/10 [01:55<17:16, 115.13s/it]            \u001b[A\n",
      "Epoch 2/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2/10:   5%|▍         | 1/22 [00:04<01:35,  4.53s/it]\u001b[A\n",
      "Epoch 2/10:   9%|▉         | 2/22 [00:08<01:18,  3.93s/it]\u001b[A\n",
      "Epoch 2/10:  14%|█▎        | 3/22 [00:13<01:30,  4.77s/it]\u001b[A\n",
      "Epoch 2/10:  18%|█▊        | 4/22 [00:19<01:33,  5.19s/it]\u001b[A\n",
      "Epoch 2/10:  23%|██▎       | 5/22 [00:25<01:31,  5.39s/it]\u001b[A\n",
      "Epoch 2/10:  27%|██▋       | 6/22 [00:30<01:22,  5.13s/it]\u001b[A\n",
      "Epoch 2/10:  32%|███▏      | 7/22 [00:35<01:16,  5.11s/it]\u001b[A\n",
      "Epoch 2/10:  36%|███▋      | 8/22 [00:39<01:06,  4.78s/it]\u001b[A\n",
      "Epoch 2/10:  41%|████      | 9/22 [00:44<01:05,  5.04s/it]\u001b[A\n",
      "Epoch 2/10:  45%|████▌     | 10/22 [00:48<00:56,  4.74s/it]\u001b[A\n",
      "Epoch 2/10:  50%|█████     | 11/22 [00:54<00:54,  4.92s/it]\u001b[A\n",
      "Epoch 2/10:  55%|█████▍    | 12/22 [00:58<00:46,  4.68s/it]\u001b[A\n",
      "Epoch 2/10:  59%|█████▉    | 13/22 [01:03<00:43,  4.85s/it]\u001b[A\n",
      "Epoch 2/10:  64%|██████▎   | 14/22 [01:09<00:40,  5.11s/it]\u001b[A\n",
      "Epoch 2/10:  68%|██████▊   | 15/22 [01:15<00:37,  5.31s/it]\u001b[A\n",
      "Epoch 2/10:  73%|███████▎  | 16/22 [01:19<00:30,  5.11s/it]\u001b[A\n",
      "Epoch 2/10:  77%|███████▋  | 17/22 [01:24<00:25,  5.14s/it]\u001b[A\n",
      "Epoch 2/10:  82%|████████▏ | 18/22 [01:28<00:19,  4.76s/it]\u001b[A\n",
      "Epoch 2/10:  86%|████████▋ | 19/22 [01:34<00:14,  4.96s/it]\u001b[A\n",
      "Epoch 2/10:  91%|█████████ | 20/22 [01:38<00:09,  4.65s/it]\u001b[A\n",
      "Epoch 2/10:  95%|█████████▌| 21/22 [01:42<00:04,  4.44s/it]\u001b[A\n",
      "Epoch 2/10: 100%|██████████| 22/22 [01:45<00:00,  4.19s/it]\u001b[A\n",
      " 20%|██        | 2/10 [03:50<15:21, 115.14s/it]            \u001b[A\n",
      "Epoch 3/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3/10:   5%|▍         | 1/22 [00:05<01:50,  5.25s/it]\u001b[A\n",
      "Epoch 3/10:   9%|▉         | 2/22 [00:10<01:43,  5.16s/it]\u001b[A\n",
      "Epoch 3/10:  14%|█▎        | 3/22 [00:16<01:43,  5.45s/it]\u001b[A\n",
      "Epoch 3/10:  18%|█▊        | 4/22 [00:20<01:32,  5.12s/it]\u001b[A\n",
      "Epoch 3/10:  23%|██▎       | 5/22 [00:25<01:27,  5.16s/it]\u001b[A\n",
      "Epoch 3/10:  27%|██▋       | 6/22 [00:29<01:11,  4.50s/it]\u001b[A\n",
      "Epoch 3/10:  32%|███▏      | 7/22 [00:34<01:10,  4.70s/it]\u001b[A\n",
      "Epoch 3/10:  36%|███▋      | 8/22 [00:39<01:07,  4.79s/it]\u001b[A\n",
      "Epoch 3/10:  41%|████      | 9/22 [00:43<01:01,  4.73s/it]\u001b[A\n",
      "Epoch 3/10:  45%|████▌     | 10/22 [00:48<00:54,  4.55s/it]\u001b[A\n",
      "Epoch 3/10:  50%|█████     | 11/22 [00:51<00:47,  4.29s/it]\u001b[A\n",
      "Epoch 3/10:  55%|█████▍    | 12/22 [00:56<00:43,  4.37s/it]\u001b[A\n",
      "Epoch 3/10:  59%|█████▉    | 13/22 [01:00<00:38,  4.32s/it]\u001b[A\n",
      "Epoch 3/10:  64%|██████▎   | 14/22 [01:04<00:34,  4.30s/it]\u001b[A\n",
      "Epoch 3/10:  68%|██████▊   | 15/22 [01:10<00:33,  4.84s/it]\u001b[A\n",
      "Epoch 3/10:  73%|███████▎  | 16/22 [01:15<00:29,  4.86s/it]\u001b[A\n",
      "Epoch 3/10:  77%|███████▋  | 17/22 [01:20<00:24,  4.92s/it]\u001b[A\n",
      "Epoch 3/10:  82%|████████▏ | 18/22 [01:27<00:21,  5.33s/it]\u001b[A\n",
      "Epoch 3/10:  86%|████████▋ | 19/22 [01:31<00:14,  4.92s/it]\u001b[A\n",
      "Epoch 3/10:  91%|█████████ | 20/22 [01:35<00:09,  4.84s/it]\u001b[A\n",
      "Epoch 3/10:  95%|█████████▌| 21/22 [01:41<00:04,  5.00s/it]\u001b[A\n",
      "Epoch 3/10: 100%|██████████| 22/22 [01:45<00:00,  4.84s/it]\u001b[A\n",
      " 30%|███       | 3/10 [05:45<13:25, 115.09s/it]            \u001b[A\n",
      "Epoch 4/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4/10:   5%|▍         | 1/22 [00:05<01:50,  5.27s/it]\u001b[A\n",
      "Epoch 4/10:   9%|▉         | 2/22 [00:08<01:24,  4.24s/it]\u001b[A\n",
      "Epoch 4/10:  14%|█▎        | 3/22 [00:14<01:32,  4.86s/it]\u001b[A\n",
      "Epoch 4/10:  18%|█▊        | 4/22 [00:19<01:27,  4.88s/it]\u001b[A\n",
      "Epoch 4/10:  23%|██▎       | 5/22 [00:24<01:27,  5.15s/it]\u001b[A\n",
      "Epoch 4/10:  27%|██▋       | 6/22 [00:30<01:23,  5.19s/it]\u001b[A\n",
      "Epoch 4/10:  32%|███▏      | 7/22 [00:36<01:23,  5.55s/it]\u001b[A\n",
      "Epoch 4/10:  36%|███▋      | 8/22 [00:39<01:08,  4.90s/it]\u001b[A\n",
      "Epoch 4/10:  41%|████      | 9/22 [00:44<01:02,  4.78s/it]\u001b[A\n",
      "Epoch 4/10:  45%|████▌     | 10/22 [00:47<00:51,  4.31s/it]\u001b[A\n",
      "Epoch 4/10:  50%|█████     | 11/22 [00:51<00:46,  4.21s/it]\u001b[A\n",
      "Epoch 4/10:  55%|█████▍    | 12/22 [00:56<00:42,  4.23s/it]\u001b[A\n",
      "Epoch 4/10:  59%|█████▉    | 13/22 [01:00<00:39,  4.43s/it]\u001b[A\n",
      "Epoch 4/10:  64%|██████▎   | 14/22 [01:04<00:33,  4.13s/it]\u001b[A\n",
      "Epoch 4/10:  68%|██████▊   | 15/22 [01:08<00:29,  4.25s/it]\u001b[A\n",
      "Epoch 4/10:  73%|███████▎  | 16/22 [01:14<00:28,  4.71s/it]\u001b[A\n",
      "Epoch 4/10:  77%|███████▋  | 17/22 [01:20<00:25,  5.07s/it]\u001b[A\n",
      "Epoch 4/10:  82%|████████▏ | 18/22 [01:25<00:20,  5.05s/it]\u001b[A\n",
      "Epoch 4/10:  86%|████████▋ | 19/22 [01:30<00:15,  5.15s/it]\u001b[A\n",
      "Epoch 4/10:  91%|█████████ | 20/22 [01:36<00:10,  5.40s/it]\u001b[A\n",
      "Epoch 4/10:  95%|█████████▌| 21/22 [01:41<00:05,  5.03s/it]\u001b[A\n",
      "Epoch 4/10: 100%|██████████| 22/22 [01:45<00:00,  4.92s/it]\u001b[A\n",
      " 40%|████      | 4/10 [07:40<11:31, 115.17s/it]            \u001b[A\n",
      "Epoch 5/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5/10:   5%|▍         | 1/22 [00:04<01:34,  4.49s/it]\u001b[A\n",
      "Epoch 5/10:   9%|▉         | 2/22 [00:10<01:49,  5.46s/it]\u001b[A\n",
      "Epoch 5/10:  14%|█▎        | 3/22 [00:16<01:45,  5.54s/it]\u001b[A\n",
      "Epoch 5/10:  18%|█▊        | 4/22 [00:19<01:26,  4.82s/it]\u001b[A\n",
      "Epoch 5/10:  23%|██▎       | 5/22 [00:24<01:20,  4.74s/it]\u001b[A\n",
      "Epoch 5/10:  27%|██▋       | 6/22 [00:29<01:18,  4.89s/it]\u001b[A\n",
      "Epoch 5/10:  32%|███▏      | 7/22 [00:32<01:04,  4.29s/it]\u001b[A\n",
      "Epoch 5/10:  36%|███▋      | 8/22 [00:38<01:06,  4.75s/it]\u001b[A\n",
      "Epoch 5/10:  41%|████      | 9/22 [00:42<00:57,  4.41s/it]\u001b[A\n",
      "Epoch 5/10:  45%|████▌     | 10/22 [00:46<00:51,  4.26s/it]\u001b[A\n",
      "Epoch 5/10:  50%|█████     | 11/22 [00:51<00:49,  4.50s/it]\u001b[A\n",
      "Epoch 5/10:  55%|█████▍    | 12/22 [00:55<00:45,  4.59s/it]\u001b[A\n",
      "Epoch 5/10:  59%|█████▉    | 13/22 [01:02<00:45,  5.04s/it]\u001b[A\n",
      "Epoch 5/10:  64%|██████▎   | 14/22 [01:07<00:40,  5.09s/it]\u001b[A\n",
      "Epoch 5/10:  68%|██████▊   | 15/22 [01:13<00:37,  5.36s/it]\u001b[A\n",
      "Epoch 5/10:  73%|███████▎  | 16/22 [01:18<00:32,  5.43s/it]\u001b[A\n",
      "Epoch 5/10:  77%|███████▋  | 17/22 [01:23<00:25,  5.11s/it]\u001b[A\n",
      "Epoch 5/10:  82%|████████▏ | 18/22 [01:27<00:20,  5.00s/it]\u001b[A\n",
      "Epoch 5/10:  86%|████████▋ | 19/22 [01:32<00:14,  4.86s/it]\u001b[A\n",
      "Epoch 5/10:  91%|█████████ | 20/22 [01:37<00:09,  4.82s/it]\u001b[A\n",
      "Epoch 5/10:  95%|█████████▌| 21/22 [01:42<00:04,  4.82s/it]\u001b[A\n",
      "Epoch 5/10: 100%|██████████| 22/22 [01:45<00:00,  4.50s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [09:35<09:36, 115.21s/it]            \u001b[A\n",
      "Epoch 6/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6/10:   5%|▍         | 1/22 [00:04<01:44,  4.98s/it]\u001b[A\n",
      "Epoch 6/10:   9%|▉         | 2/22 [00:09<01:39,  4.98s/it]\u001b[A\n",
      "Epoch 6/10:  14%|█▎        | 3/22 [00:14<01:31,  4.82s/it]\u001b[A\n",
      "Epoch 6/10:  18%|█▊        | 4/22 [00:19<01:30,  5.05s/it]\u001b[A\n",
      "Epoch 6/10:  23%|██▎       | 5/22 [00:25<01:26,  5.11s/it]\u001b[A\n",
      "Epoch 6/10:  27%|██▋       | 6/22 [00:28<01:13,  4.58s/it]\u001b[A\n",
      "Epoch 6/10:  32%|███▏      | 7/22 [00:33<01:09,  4.64s/it]\u001b[A\n",
      "Epoch 6/10:  36%|███▋      | 8/22 [00:38<01:08,  4.88s/it]\u001b[A\n",
      "Epoch 6/10:  41%|████      | 9/22 [00:44<01:04,  4.99s/it]\u001b[A\n",
      "Epoch 6/10:  45%|████▌     | 10/22 [00:48<00:59,  4.93s/it]\u001b[A\n",
      "Epoch 6/10:  50%|█████     | 11/22 [00:53<00:51,  4.71s/it]\u001b[A\n",
      "Epoch 6/10:  55%|█████▍    | 12/22 [00:57<00:46,  4.66s/it]\u001b[A\n",
      "Epoch 6/10:  59%|█████▉    | 13/22 [01:01<00:39,  4.42s/it]\u001b[A\n",
      "Epoch 6/10:  64%|██████▎   | 14/22 [01:06<00:36,  4.54s/it]\u001b[A\n",
      "Epoch 6/10:  68%|██████▊   | 15/22 [01:12<00:35,  5.05s/it]\u001b[A\n",
      "Epoch 6/10:  73%|███████▎  | 16/22 [01:17<00:29,  4.99s/it]\u001b[A\n",
      "Epoch 6/10:  77%|███████▋  | 17/22 [01:21<00:24,  4.82s/it]\u001b[A\n",
      "Epoch 6/10:  82%|████████▏ | 18/22 [01:25<00:18,  4.54s/it]\u001b[A\n",
      "Epoch 6/10:  86%|████████▋ | 19/22 [01:30<00:13,  4.60s/it]\u001b[A\n",
      "Epoch 6/10:  91%|█████████ | 20/22 [01:35<00:09,  4.73s/it]\u001b[A\n",
      "Epoch 6/10:  95%|█████████▌| 21/22 [01:41<00:05,  5.12s/it]\u001b[A\n",
      "Epoch 6/10: 100%|██████████| 22/22 [01:45<00:00,  4.82s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [11:31<07:40, 115.21s/it]            \u001b[A\n",
      "Epoch 7/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7/10:   5%|▍         | 1/22 [00:04<01:34,  4.50s/it]\u001b[A\n",
      "Epoch 7/10:   9%|▉         | 2/22 [00:08<01:26,  4.35s/it]\u001b[A\n",
      "Epoch 7/10:  14%|█▎        | 3/22 [00:14<01:32,  4.88s/it]\u001b[A\n",
      "Epoch 7/10:  18%|█▊        | 4/22 [00:19<01:28,  4.90s/it]\u001b[A\n",
      "Epoch 7/10:  23%|██▎       | 5/22 [00:24<01:23,  4.90s/it]\u001b[A\n",
      "Epoch 7/10:  27%|██▋       | 6/22 [00:29<01:23,  5.22s/it]\u001b[A\n",
      "Epoch 7/10:  32%|███▏      | 7/22 [00:36<01:23,  5.55s/it]\u001b[A\n",
      "Epoch 7/10:  36%|███▋      | 8/22 [00:41<01:16,  5.45s/it]\u001b[A\n",
      "Epoch 7/10:  41%|████      | 9/22 [00:45<01:05,  5.06s/it]\u001b[A\n",
      "Epoch 7/10:  45%|████▌     | 10/22 [00:50<01:00,  5.05s/it]\u001b[A\n",
      "Epoch 7/10:  50%|█████     | 11/22 [00:55<00:54,  4.98s/it]\u001b[A\n",
      "Epoch 7/10:  55%|█████▍    | 12/22 [01:00<00:49,  4.90s/it]\u001b[A\n",
      "Epoch 7/10:  59%|█████▉    | 13/22 [01:05<00:44,  4.91s/it]\u001b[A\n",
      "Epoch 7/10:  64%|██████▎   | 14/22 [01:09<00:38,  4.79s/it]\u001b[A\n",
      "Epoch 7/10:  68%|██████▊   | 15/22 [01:13<00:30,  4.39s/it]\u001b[A\n",
      "Epoch 7/10:  73%|███████▎  | 16/22 [01:17<00:26,  4.43s/it]\u001b[A\n",
      "Epoch 7/10:  77%|███████▋  | 17/22 [01:22<00:23,  4.65s/it]\u001b[A\n",
      "Epoch 7/10:  82%|████████▏ | 18/22 [01:28<00:20,  5.09s/it]\u001b[A\n",
      "Epoch 7/10:  86%|████████▋ | 19/22 [01:33<00:15,  5.04s/it]\u001b[A\n",
      "Epoch 7/10:  91%|█████████ | 20/22 [01:37<00:09,  4.75s/it]\u001b[A\n",
      "Epoch 7/10:  95%|█████████▌| 21/22 [01:41<00:04,  4.47s/it]\u001b[A\n",
      "Epoch 7/10: 100%|██████████| 22/22 [01:45<00:00,  4.34s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [13:26<05:45, 115.22s/it]            \u001b[A\n",
      "Epoch 8/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8/10:   5%|▍         | 1/22 [00:05<02:04,  5.91s/it]\u001b[A\n",
      "Epoch 8/10:   9%|▉         | 2/22 [00:09<01:35,  4.77s/it]\u001b[A\n",
      "Epoch 8/10:  14%|█▎        | 3/22 [00:14<01:25,  4.48s/it]\u001b[A\n",
      "Epoch 8/10:  18%|█▊        | 4/22 [00:18<01:23,  4.61s/it]\u001b[A\n",
      "Epoch 8/10:  23%|██▎       | 5/22 [00:24<01:24,  4.95s/it]\u001b[A\n",
      "Epoch 8/10:  27%|██▋       | 6/22 [00:30<01:23,  5.24s/it]\u001b[A\n",
      "Epoch 8/10:  32%|███▏      | 7/22 [00:34<01:14,  4.99s/it]\u001b[A\n",
      "Epoch 8/10:  36%|███▋      | 8/22 [00:39<01:08,  4.89s/it]\u001b[A\n",
      "Epoch 8/10:  41%|████      | 9/22 [00:43<01:01,  4.76s/it]\u001b[A\n",
      "Epoch 8/10:  45%|████▌     | 10/22 [00:47<00:54,  4.54s/it]\u001b[A\n",
      "Epoch 8/10:  50%|█████     | 11/22 [00:53<00:53,  4.89s/it]\u001b[A\n",
      "Epoch 8/10:  55%|█████▍    | 12/22 [00:58<00:47,  4.77s/it]\u001b[A\n",
      "Epoch 8/10:  59%|█████▉    | 13/22 [01:02<00:42,  4.75s/it]\u001b[A\n",
      "Epoch 8/10:  64%|██████▎   | 14/22 [01:07<00:38,  4.87s/it]\u001b[A\n",
      "Epoch 8/10:  68%|██████▊   | 15/22 [01:11<00:32,  4.58s/it]\u001b[A\n",
      "Epoch 8/10:  73%|███████▎  | 16/22 [01:17<00:30,  5.00s/it]\u001b[A\n",
      "Epoch 8/10:  77%|███████▋  | 17/22 [01:21<00:23,  4.67s/it]\u001b[A\n",
      "Epoch 8/10:  82%|████████▏ | 18/22 [01:27<00:19,  4.91s/it]\u001b[A\n",
      "Epoch 8/10:  86%|████████▋ | 19/22 [01:32<00:14,  4.91s/it]\u001b[A\n",
      "Epoch 8/10:  91%|█████████ | 20/22 [01:37<00:09,  4.93s/it]\u001b[A\n",
      "Epoch 8/10:  95%|█████████▌| 21/22 [01:41<00:04,  4.70s/it]\u001b[A\n",
      "Epoch 8/10: 100%|██████████| 22/22 [01:45<00:00,  4.65s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [15:21<03:50, 115.21s/it]            \u001b[A\n",
      "Epoch 9/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9/10:   5%|▍         | 1/22 [00:03<01:21,  3.90s/it]\u001b[A\n",
      "Epoch 9/10:   9%|▉         | 2/22 [00:08<01:27,  4.39s/it]\u001b[A\n",
      "Epoch 9/10:  14%|█▎        | 3/22 [00:14<01:34,  4.97s/it]\u001b[A\n",
      "Epoch 9/10:  18%|█▊        | 4/22 [00:18<01:25,  4.76s/it]\u001b[A\n",
      "Epoch 9/10:  23%|██▎       | 5/22 [00:23<01:21,  4.78s/it]\u001b[A\n",
      "Epoch 9/10:  27%|██▋       | 6/22 [00:29<01:22,  5.19s/it]\u001b[A\n",
      "Epoch 9/10:  32%|███▏      | 7/22 [00:34<01:14,  4.98s/it]\u001b[A\n",
      "Epoch 9/10:  36%|███▋      | 8/22 [00:39<01:12,  5.19s/it]\u001b[A\n",
      "Epoch 9/10:  41%|████      | 9/22 [00:43<01:03,  4.88s/it]\u001b[A\n",
      "Epoch 9/10:  45%|████▌     | 10/22 [00:48<00:56,  4.69s/it]\u001b[A\n",
      "Epoch 9/10:  50%|█████     | 11/22 [00:54<00:57,  5.21s/it]\u001b[A\n",
      "Epoch 9/10:  55%|█████▍    | 12/22 [00:58<00:48,  4.86s/it]\u001b[A\n",
      "Epoch 9/10:  59%|█████▉    | 13/22 [01:03<00:43,  4.83s/it]\u001b[A\n",
      "Epoch 9/10:  64%|██████▎   | 14/22 [01:08<00:39,  4.89s/it]\u001b[A\n",
      "Epoch 9/10:  68%|██████▊   | 15/22 [01:13<00:33,  4.81s/it]\u001b[A\n",
      "Epoch 9/10:  73%|███████▎  | 16/22 [01:17<00:28,  4.75s/it]\u001b[A\n",
      "Epoch 9/10:  77%|███████▋  | 17/22 [01:21<00:22,  4.56s/it]\u001b[A\n",
      "Epoch 9/10:  82%|████████▏ | 18/22 [01:26<00:18,  4.64s/it]\u001b[A\n",
      "Epoch 9/10:  86%|████████▋ | 19/22 [01:31<00:14,  4.69s/it]\u001b[A\n",
      "Epoch 9/10:  91%|█████████ | 20/22 [01:35<00:09,  4.58s/it]\u001b[A\n",
      "Epoch 9/10:  95%|█████████▌| 21/22 [01:41<00:04,  4.98s/it]\u001b[A\n",
      "Epoch 9/10: 100%|██████████| 22/22 [01:45<00:00,  4.71s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [17:16<01:55, 115.21s/it]            \u001b[A\n",
      "Epoch 10/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10/10:   5%|▍         | 1/22 [00:04<01:39,  4.73s/it]\u001b[A\n",
      "Epoch 10/10:   9%|▉         | 2/22 [00:10<01:46,  5.35s/it]\u001b[A\n",
      "Epoch 10/10:  14%|█▎        | 3/22 [00:15<01:35,  5.02s/it]\u001b[A\n",
      "Epoch 10/10:  18%|█▊        | 4/22 [00:20<01:35,  5.30s/it]\u001b[A\n",
      "Epoch 10/10:  23%|██▎       | 5/22 [00:26<01:30,  5.34s/it]\u001b[A\n",
      "Epoch 10/10:  27%|██▋       | 6/22 [00:30<01:17,  4.87s/it]\u001b[A\n",
      "Epoch 10/10:  32%|███▏      | 7/22 [00:34<01:09,  4.62s/it]\u001b[A\n",
      "Epoch 10/10:  36%|███▋      | 8/22 [00:39<01:07,  4.81s/it]\u001b[A\n",
      "Epoch 10/10:  41%|████      | 9/22 [00:44<01:02,  4.78s/it]\u001b[A\n",
      "Epoch 10/10:  45%|████▌     | 10/22 [00:49<00:58,  4.89s/it]\u001b[A\n",
      "Epoch 10/10:  50%|█████     | 11/22 [00:54<00:53,  4.84s/it]\u001b[A\n",
      "Epoch 10/10:  55%|█████▍    | 12/22 [00:58<00:47,  4.73s/it]\u001b[A\n",
      "Epoch 10/10:  59%|█████▉    | 13/22 [01:02<00:39,  4.43s/it]\u001b[A\n",
      "Epoch 10/10:  64%|██████▎   | 14/22 [01:06<00:34,  4.37s/it]\u001b[A\n",
      "Epoch 10/10:  68%|██████▊   | 15/22 [01:10<00:30,  4.38s/it]\u001b[A\n",
      "Epoch 10/10:  73%|███████▎  | 16/22 [01:15<00:26,  4.39s/it]\u001b[A\n",
      "Epoch 10/10:  77%|███████▋  | 17/22 [01:20<00:23,  4.65s/it]\u001b[A\n",
      "Epoch 10/10:  82%|████████▏ | 18/22 [01:25<00:19,  4.77s/it]\u001b[A\n",
      "Epoch 10/10:  86%|████████▋ | 19/22 [01:31<00:15,  5.17s/it]\u001b[A\n",
      "Epoch 10/10:  91%|█████████ | 20/22 [01:35<00:09,  4.81s/it]\u001b[A\n",
      "Epoch 10/10:  95%|█████████▌| 21/22 [01:40<00:04,  4.92s/it]\u001b[A\n",
      "Epoch 10/10: 100%|██████████| 22/22 [01:45<00:00,  4.88s/it]\u001b[A\n",
      "100%|██████████| 10/10 [19:11<00:00, 115.20s/it]            \u001b[A\n",
      "[I 2024-08-16 00:50:29,683] Trial 1 finished with value: 0.010871088691055774 and parameters: {'hidden_channels': 128, 'num_layers': 2, 'heads': 16, 'dropout_rate': 0.46064895467319084, 'lr': 6.74975330801571e-05}. Best is trial 1 with value: 0.010871088691055774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 Results ---\n",
      "Hyperparameters:\n",
      "  hidden_channels: 128\n",
      "  num_layers: 2\n",
      "  heads: 16\n",
      "  dropout_rate: 0.46064895467319084\n",
      "  lr: 6.74975330801571e-05\n",
      "\n",
      "Current Model Architecture:\n",
      "ComplexGAT(\n",
      "  (conv1): GATConv(5, 128, heads=16)\n",
      "  (convs): ModuleList()\n",
      "  (conv_last): GATConv(2048, 128, heads=1)\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Best Validation Loss for this trial: 1.08711e-02\n",
      "Best Overall Validation Loss: 1.08711e-02 (Trial 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Epoch 1/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1/10:   5%|▍         | 1/22 [00:10<03:44, 10.71s/it]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 2/22 [00:24<04:10, 12.53s/it]\u001b[A\n",
      "Epoch 1/10:  14%|█▎        | 3/22 [00:35<03:44, 11.84s/it]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 4/22 [00:51<04:02, 13.46s/it]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 5/22 [01:05<03:49, 13.50s/it]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 6/22 [01:13<03:06, 11.65s/it]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 7/22 [01:28<03:13, 12.90s/it]\u001b[A\n",
      "Epoch 1/10:  36%|███▋      | 8/22 [01:40<02:56, 12.60s/it]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 9/22 [01:50<02:31, 11.65s/it]\u001b[A\n",
      "Epoch 1/10:  45%|████▌     | 10/22 [02:01<02:17, 11.42s/it]\u001b[A\n",
      "Epoch 1/10:  50%|█████     | 11/22 [02:12<02:06, 11.48s/it]\u001b[A\n",
      "Epoch 1/10:  55%|█████▍    | 12/22 [02:25<01:59, 11.97s/it]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 13/22 [02:40<01:54, 12.73s/it]\u001b[A\n",
      "Epoch 1/10:  64%|██████▎   | 14/22 [02:53<01:43, 12.94s/it]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 15/22 [03:06<01:29, 12.85s/it]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 16/22 [03:20<01:19, 13.18s/it]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 17/22 [03:35<01:08, 13.72s/it]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 18/22 [03:47<00:52, 13.19s/it]\u001b[A\n",
      "Epoch 1/10:  86%|████████▋ | 19/22 [03:59<00:38, 12.98s/it]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 20/22 [04:13<00:26, 13.23s/it]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▌| 21/22 [04:25<00:13, 13.03s/it]\u001b[A\n",
      "Epoch 1/10: 100%|██████████| 22/22 [04:35<00:00, 11.84s/it]\u001b[A\n",
      " 10%|█         | 1/10 [05:00<45:04, 300.50s/it]            \u001b[A\n",
      "Epoch 2/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2/10:   5%|▍         | 1/22 [00:09<03:18,  9.44s/it]\u001b[A\n",
      "Epoch 2/10:   9%|▉         | 2/22 [00:23<04:04, 12.21s/it]\u001b[A\n",
      "Epoch 2/10:  14%|█▎        | 3/22 [00:36<03:59, 12.59s/it]\u001b[A\n",
      "Epoch 2/10:  18%|█▊        | 4/22 [00:51<04:02, 13.47s/it]\u001b[A\n",
      "Epoch 2/10:  23%|██▎       | 5/22 [01:03<03:41, 13.00s/it]\u001b[A\n",
      "Epoch 2/10:  27%|██▋       | 6/22 [01:16<03:29, 13.12s/it]\u001b[A\n",
      "Epoch 2/10:  32%|███▏      | 7/22 [01:31<03:25, 13.69s/it]\u001b[A\n",
      "Epoch 2/10:  36%|███▋      | 8/22 [01:44<03:05, 13.22s/it]\u001b[A\n",
      "Epoch 2/10:  41%|████      | 9/22 [01:53<02:36, 12.01s/it]\u001b[A\n",
      "Epoch 2/10:  45%|████▌     | 10/22 [02:07<02:33, 12.78s/it]\u001b[A\n",
      "Epoch 2/10:  50%|█████     | 11/22 [02:20<02:20, 12.74s/it]\u001b[A\n",
      "Epoch 2/10:  55%|█████▍    | 12/22 [02:29<01:54, 11.50s/it]\u001b[A\n",
      "Epoch 2/10:  59%|█████▉    | 13/22 [02:41<01:46, 11.83s/it]\u001b[A\n",
      "Epoch 2/10:  64%|██████▎   | 14/22 [02:55<01:40, 12.54s/it]\u001b[A\n",
      "Epoch 2/10:  68%|██████▊   | 15/22 [03:12<01:35, 13.61s/it]\u001b[A\n",
      "Epoch 2/10:  73%|███████▎  | 16/22 [03:24<01:18, 13.13s/it]\u001b[A\n",
      "Epoch 2/10:  77%|███████▋  | 17/22 [03:36<01:04, 12.97s/it]\u001b[A\n",
      "Epoch 2/10:  82%|████████▏ | 18/22 [03:49<00:51, 12.85s/it]\u001b[A\n",
      "Epoch 2/10:  86%|████████▋ | 19/22 [04:05<00:41, 13.74s/it]\u001b[A\n",
      "Epoch 2/10:  91%|█████████ | 20/22 [04:16<00:26, 13.18s/it]\u001b[A\n",
      "Epoch 2/10:  95%|█████████▌| 21/22 [04:26<00:11, 11.99s/it]\u001b[A\n",
      "Epoch 2/10: 100%|██████████| 22/22 [04:34<00:00, 11.04s/it]\u001b[A\n",
      " 20%|██        | 2/10 [10:00<40:03, 300.39s/it]            \u001b[A\n",
      "Epoch 3/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3/10:   5%|▍         | 1/22 [00:15<05:31, 15.77s/it]\u001b[A\n",
      "Epoch 3/10:   9%|▉         | 2/22 [00:31<05:10, 15.52s/it]\u001b[A\n",
      "Epoch 3/10:  14%|█▎        | 3/22 [00:46<04:57, 15.64s/it]\u001b[A\n",
      "Epoch 3/10:  18%|█▊        | 4/22 [00:56<03:59, 13.30s/it]\u001b[A\n",
      "Epoch 3/10:  23%|██▎       | 5/22 [01:07<03:31, 12.47s/it]\u001b[A\n",
      "Epoch 3/10:  27%|██▋       | 6/22 [01:19<03:17, 12.35s/it]\u001b[A\n",
      "Epoch 3/10:  32%|███▏      | 7/22 [01:30<02:58, 11.87s/it]\u001b[A\n",
      "Epoch 3/10:  36%|███▋      | 8/22 [01:44<02:55, 12.56s/it]\u001b[A\n",
      "Epoch 3/10:  41%|████      | 9/22 [01:55<02:35, 11.95s/it]\u001b[A\n",
      "Epoch 3/10:  45%|████▌     | 10/22 [02:08<02:28, 12.41s/it]\u001b[A\n",
      "Epoch 3/10:  50%|█████     | 11/22 [02:21<02:18, 12.61s/it]\u001b[A\n",
      "Epoch 3/10:  55%|█████▍    | 12/22 [02:35<02:09, 12.97s/it]\u001b[A\n",
      "Epoch 3/10:  59%|█████▉    | 13/22 [02:45<01:49, 12.15s/it]\u001b[A\n",
      "Epoch 3/10:  64%|██████▎   | 14/22 [02:57<01:36, 12.09s/it]\u001b[A\n",
      "Epoch 3/10:  68%|██████▊   | 15/22 [03:10<01:25, 12.19s/it]\u001b[A\n",
      "Epoch 3/10:  73%|███████▎  | 16/22 [03:21<01:11, 11.91s/it]\u001b[A\n",
      "Epoch 3/10:  77%|███████▋  | 17/22 [03:34<01:01, 12.35s/it]\u001b[A\n",
      "Epoch 3/10:  82%|████████▏ | 18/22 [03:46<00:48, 12.12s/it]\u001b[A\n",
      "Epoch 3/10:  86%|████████▋ | 19/22 [03:59<00:37, 12.45s/it]\u001b[A\n",
      "Epoch 3/10:  91%|█████████ | 20/22 [04:10<00:24, 12.11s/it]\u001b[A\n",
      "Epoch 3/10:  95%|█████████▌| 21/22 [04:21<00:11, 11.69s/it]\u001b[A\n",
      "Epoch 3/10: 100%|██████████| 22/22 [04:34<00:00, 12.10s/it]\u001b[A\n",
      " 30%|███       | 3/10 [15:00<35:01, 300.24s/it]            \u001b[A\n",
      "Epoch 4/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4/10:   5%|▍         | 1/22 [00:12<04:15, 12.19s/it]\u001b[A\n",
      "Epoch 4/10:   9%|▉         | 2/22 [00:24<04:07, 12.40s/it]\u001b[A\n",
      "Epoch 4/10:  14%|█▎        | 3/22 [00:36<03:47, 11.97s/it]\u001b[A\n",
      "Epoch 4/10:  18%|█▊        | 4/22 [00:50<03:52, 12.93s/it]\u001b[A\n",
      "Epoch 4/10:  23%|██▎       | 5/22 [01:01<03:30, 12.36s/it]\u001b[A\n",
      "Epoch 4/10:  27%|██▋       | 6/22 [01:14<03:19, 12.47s/it]\u001b[A\n",
      "Epoch 4/10:  32%|███▏      | 7/22 [01:26<03:05, 12.38s/it]\u001b[A\n",
      "Epoch 4/10:  36%|███▋      | 8/22 [01:40<02:57, 12.69s/it]\u001b[A\n",
      "Epoch 4/10:  41%|████      | 9/22 [01:51<02:40, 12.31s/it]\u001b[A\n",
      "Epoch 4/10:  45%|████▌     | 10/22 [02:03<02:25, 12.11s/it]\u001b[A\n",
      "Epoch 4/10:  50%|█████     | 11/22 [02:17<02:18, 12.63s/it]\u001b[A\n",
      "Epoch 4/10:  55%|█████▍    | 12/22 [02:31<02:10, 13.02s/it]\u001b[A\n",
      "Epoch 4/10:  59%|█████▉    | 13/22 [02:43<01:55, 12.82s/it]\u001b[A\n",
      "Epoch 4/10:  64%|██████▎   | 14/22 [02:57<01:45, 13.25s/it]\u001b[A\n",
      "Epoch 4/10:  68%|██████▊   | 15/22 [03:10<01:32, 13.22s/it]\u001b[A\n",
      "Epoch 4/10:  73%|███████▎  | 16/22 [03:22<01:16, 12.72s/it]\u001b[A\n",
      "Epoch 4/10:  77%|███████▋  | 17/22 [03:35<01:04, 12.87s/it]\u001b[A\n",
      "Epoch 4/10:  82%|████████▏ | 18/22 [03:46<00:48, 12.18s/it]\u001b[A\n",
      "Epoch 4/10:  86%|████████▋ | 19/22 [03:57<00:35, 11.82s/it]\u001b[A\n",
      "Epoch 4/10:  91%|█████████ | 20/22 [04:08<00:23, 11.61s/it]\u001b[A\n",
      "Epoch 4/10:  95%|█████████▌| 21/22 [04:20<00:11, 11.69s/it]\u001b[A\n",
      "Epoch 4/10: 100%|██████████| 22/22 [04:34<00:00, 12.63s/it]\u001b[A\n",
      " 40%|████      | 4/10 [20:01<30:01, 300.29s/it]            \u001b[A\n",
      "Epoch 5/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5/10:   5%|▍         | 1/22 [00:12<04:18, 12.30s/it]\u001b[A\n",
      "Epoch 5/10:   9%|▉         | 2/22 [00:23<03:57, 11.86s/it]\u001b[A\n",
      "Epoch 5/10:  14%|█▎        | 3/22 [00:35<03:45, 11.84s/it]\u001b[A\n",
      "Epoch 5/10:  18%|█▊        | 4/22 [00:47<03:31, 11.76s/it]\u001b[A\n",
      "Epoch 5/10:  23%|██▎       | 5/22 [01:04<03:51, 13.65s/it]\u001b[A\n",
      "Epoch 5/10:  27%|██▋       | 6/22 [01:19<03:46, 14.15s/it]\u001b[A\n",
      "Epoch 5/10:  32%|███▏      | 7/22 [01:32<03:27, 13.83s/it]\u001b[A\n",
      "Epoch 5/10:  36%|███▋      | 8/22 [01:45<03:08, 13.49s/it]\u001b[A\n",
      "Epoch 5/10:  41%|████      | 9/22 [01:54<02:35, 11.98s/it]\u001b[A\n",
      "Epoch 5/10:  45%|████▌     | 10/22 [02:04<02:17, 11.48s/it]\u001b[A\n",
      "Epoch 5/10:  50%|█████     | 11/22 [02:17<02:11, 11.97s/it]\u001b[A\n",
      "Epoch 5/10:  55%|█████▍    | 12/22 [02:30<02:02, 12.29s/it]\u001b[A\n",
      "Epoch 5/10:  59%|█████▉    | 13/22 [02:42<01:48, 12.10s/it]\u001b[A\n",
      "Epoch 5/10:  64%|██████▎   | 14/22 [02:53<01:36, 12.02s/it]\u001b[A\n",
      "Epoch 5/10:  68%|██████▊   | 15/22 [03:04<01:21, 11.69s/it]\u001b[A\n",
      "Epoch 5/10:  73%|███████▎  | 16/22 [03:22<01:20, 13.47s/it]\u001b[A\n",
      "Epoch 5/10:  77%|███████▋  | 17/22 [03:33<01:03, 12.76s/it]\u001b[A\n",
      "Epoch 5/10:  82%|████████▏ | 18/22 [03:42<00:46, 11.65s/it]\u001b[A\n",
      "Epoch 5/10:  86%|████████▋ | 19/22 [03:55<00:35, 11.93s/it]\u001b[A\n",
      "Epoch 5/10:  91%|█████████ | 20/22 [04:08<00:24, 12.20s/it]\u001b[A\n",
      "Epoch 5/10:  95%|█████████▌| 21/22 [04:24<00:13, 13.36s/it]\u001b[A\n",
      "Epoch 5/10: 100%|██████████| 22/22 [04:35<00:00, 12.66s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [25:01<25:01, 300.39s/it]            \u001b[A\n",
      "Epoch 6/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6/10:   5%|▍         | 1/22 [00:10<03:48, 10.90s/it]\u001b[A\n",
      "Epoch 6/10:   9%|▉         | 2/22 [00:23<03:56, 11.82s/it]\u001b[A\n",
      "Epoch 6/10:  14%|█▎        | 3/22 [00:39<04:24, 13.94s/it]\u001b[A\n",
      "Epoch 6/10:  18%|█▊        | 4/22 [00:54<04:12, 14.05s/it]\u001b[A\n",
      "Epoch 6/10:  23%|██▎       | 5/22 [01:04<03:38, 12.88s/it]\u001b[A\n",
      "Epoch 6/10:  27%|██▋       | 6/22 [01:16<03:19, 12.49s/it]\u001b[A\n",
      "Epoch 6/10:  32%|███▏      | 7/22 [01:31<03:17, 13.18s/it]\u001b[A\n",
      "Epoch 6/10:  36%|███▋      | 8/22 [01:44<03:04, 13.15s/it]\u001b[A\n",
      "Epoch 6/10:  41%|████      | 9/22 [01:55<02:43, 12.58s/it]\u001b[A\n",
      "Epoch 6/10:  45%|████▌     | 10/22 [02:05<02:21, 11.77s/it]\u001b[A\n",
      "Epoch 6/10:  50%|█████     | 11/22 [02:18<02:13, 12.17s/it]\u001b[A\n",
      "Epoch 6/10:  55%|█████▍    | 12/22 [02:31<02:03, 12.35s/it]\u001b[A\n",
      "Epoch 6/10:  59%|█████▉    | 13/22 [02:42<01:48, 12.04s/it]\u001b[A\n",
      "Epoch 6/10:  64%|██████▎   | 14/22 [02:57<01:42, 12.77s/it]\u001b[A\n",
      "Epoch 6/10:  68%|██████▊   | 15/22 [03:11<01:32, 13.16s/it]\u001b[A\n",
      "Epoch 6/10:  73%|███████▎  | 16/22 [03:26<01:22, 13.77s/it]\u001b[A\n",
      "Epoch 6/10:  77%|███████▋  | 17/22 [03:41<01:10, 14.02s/it]\u001b[A\n",
      "Epoch 6/10:  82%|████████▏ | 18/22 [03:52<00:53, 13.29s/it]\u001b[A\n",
      "Epoch 6/10:  86%|████████▋ | 19/22 [04:02<00:36, 12.27s/it]\u001b[A\n",
      "Epoch 6/10:  91%|█████████ | 20/22 [04:15<00:25, 12.54s/it]\u001b[A\n",
      "Epoch 6/10:  95%|█████████▌| 21/22 [04:25<00:11, 11.83s/it]\u001b[A\n",
      "Epoch 6/10: 100%|██████████| 22/22 [04:35<00:00, 11.04s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [30:02<20:01, 300.41s/it]            \u001b[A\n",
      "Epoch 7/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7/10:   5%|▍         | 1/22 [00:10<03:31, 10.10s/it]\u001b[A\n",
      "Epoch 7/10:   9%|▉         | 2/22 [00:20<03:28, 10.43s/it]\u001b[A\n",
      "Epoch 7/10:  14%|█▎        | 3/22 [00:34<03:47, 11.96s/it]\u001b[A\n",
      "Epoch 7/10:  18%|█▊        | 4/22 [00:49<03:56, 13.12s/it]\u001b[A\n",
      "Epoch 7/10:  23%|██▎       | 5/22 [01:02<03:43, 13.15s/it]\u001b[A\n",
      "Epoch 7/10:  27%|██▋       | 6/22 [01:11<03:09, 11.82s/it]\u001b[A\n",
      "Epoch 7/10:  32%|███▏      | 7/22 [01:23<02:58, 11.88s/it]\u001b[A\n",
      "Epoch 7/10:  36%|███▋      | 8/22 [01:37<02:53, 12.40s/it]\u001b[A\n",
      "Epoch 7/10:  41%|████      | 9/22 [01:51<02:46, 12.84s/it]\u001b[A\n",
      "Epoch 7/10:  45%|████▌     | 10/22 [02:04<02:34, 12.90s/it]\u001b[A\n",
      "Epoch 7/10:  50%|█████     | 11/22 [02:17<02:24, 13.13s/it]\u001b[A\n",
      "Epoch 7/10:  55%|█████▍    | 12/22 [02:28<02:04, 12.48s/it]\u001b[A\n",
      "Epoch 7/10:  59%|█████▉    | 13/22 [02:41<01:53, 12.61s/it]\u001b[A\n",
      "Epoch 7/10:  64%|██████▎   | 14/22 [02:53<01:38, 12.31s/it]\u001b[A\n",
      "Epoch 7/10:  68%|██████▊   | 15/22 [03:07<01:29, 12.78s/it]\u001b[A\n",
      "Epoch 7/10:  73%|███████▎  | 16/22 [03:21<01:18, 13.07s/it]\u001b[A\n",
      "Epoch 7/10:  77%|███████▋  | 17/22 [03:37<01:10, 14.04s/it]\u001b[A\n",
      "Epoch 7/10:  82%|████████▏ | 18/22 [03:50<00:55, 13.81s/it]\u001b[A\n",
      "Epoch 7/10:  86%|████████▋ | 19/22 [04:00<00:37, 12.64s/it]\u001b[A\n",
      "Epoch 7/10:  91%|█████████ | 20/22 [04:13<00:25, 12.73s/it]\u001b[A\n",
      "Epoch 7/10:  95%|█████████▌| 21/22 [04:25<00:12, 12.55s/it]\u001b[A\n",
      "Epoch 7/10: 100%|██████████| 22/22 [04:35<00:00, 11.69s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [35:02<15:01, 300.49s/it]            \u001b[A\n",
      "Epoch 8/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8/10:   5%|▍         | 1/22 [00:15<05:19, 15.19s/it]\u001b[A\n",
      "Epoch 8/10:   9%|▉         | 2/22 [00:27<04:27, 13.38s/it]\u001b[A\n",
      "Epoch 8/10:  14%|█▎        | 3/22 [00:37<03:46, 11.90s/it]\u001b[A\n",
      "Epoch 8/10:  18%|█▊        | 4/22 [00:49<03:35, 11.96s/it]\u001b[A\n",
      "Epoch 8/10:  23%|██▎       | 5/22 [01:01<03:22, 11.90s/it]\u001b[A\n",
      "Epoch 8/10:  27%|██▋       | 6/22 [01:12<03:06, 11.64s/it]\u001b[A\n",
      "Epoch 8/10:  32%|███▏      | 7/22 [01:22<02:46, 11.10s/it]\u001b[A\n",
      "Epoch 8/10:  36%|███▋      | 8/22 [01:35<02:42, 11.60s/it]\u001b[A\n",
      "Epoch 8/10:  41%|████      | 9/22 [01:48<02:37, 12.08s/it]\u001b[A\n",
      "Epoch 8/10:  45%|████▌     | 10/22 [02:01<02:31, 12.58s/it]\u001b[A\n",
      "Epoch 8/10:  50%|█████     | 11/22 [02:14<02:16, 12.44s/it]\u001b[A\n",
      "Epoch 8/10:  55%|█████▍    | 12/22 [02:25<02:00, 12.06s/it]\u001b[A\n",
      "Epoch 8/10:  59%|█████▉    | 13/22 [02:39<01:55, 12.86s/it]\u001b[A\n",
      "Epoch 8/10:  64%|██████▎   | 14/22 [02:51<01:39, 12.41s/it]\u001b[A\n",
      "Epoch 8/10:  68%|██████▊   | 15/22 [03:03<01:27, 12.44s/it]\u001b[A\n",
      "Epoch 8/10:  73%|███████▎  | 16/22 [03:17<01:17, 12.88s/it]\u001b[A\n",
      "Epoch 8/10:  77%|███████▋  | 17/22 [03:29<01:03, 12.64s/it]\u001b[A\n",
      "Epoch 8/10:  82%|████████▏ | 18/22 [03:41<00:50, 12.51s/it]\u001b[A\n",
      "Epoch 8/10:  86%|████████▋ | 19/22 [03:57<00:40, 13.50s/it]\u001b[A\n",
      "Epoch 8/10:  91%|█████████ | 20/22 [04:12<00:27, 13.98s/it]\u001b[A\n",
      "Epoch 8/10:  95%|█████████▌| 21/22 [04:23<00:13, 13.09s/it]\u001b[A\n",
      "Epoch 8/10: 100%|██████████| 22/22 [04:35<00:00, 12.52s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [40:03<10:00, 300.48s/it]            \u001b[A\n",
      "Epoch 9/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9/10:   5%|▍         | 1/22 [00:12<04:27, 12.74s/it]\u001b[A\n",
      "Epoch 9/10:   9%|▉         | 2/22 [00:25<04:12, 12.61s/it]\u001b[A\n",
      "Epoch 9/10:  14%|█▎        | 3/22 [00:37<03:58, 12.53s/it]\u001b[A\n",
      "Epoch 9/10:  18%|█▊        | 4/22 [00:47<03:28, 11.61s/it]\u001b[A\n",
      "Epoch 9/10:  23%|██▎       | 5/22 [00:59<03:14, 11.44s/it]\u001b[A\n",
      "Epoch 9/10:  27%|██▋       | 6/22 [01:14<03:25, 12.86s/it]\u001b[A\n",
      "Epoch 9/10:  32%|███▏      | 7/22 [01:28<03:17, 13.14s/it]\u001b[A\n",
      "Epoch 9/10:  36%|███▋      | 8/22 [01:42<03:10, 13.61s/it]\u001b[A\n",
      "Epoch 9/10:  41%|████      | 9/22 [01:53<02:45, 12.71s/it]\u001b[A\n",
      "Epoch 9/10:  45%|████▌     | 10/22 [02:08<02:39, 13.31s/it]\u001b[A\n",
      "Epoch 9/10:  50%|█████     | 11/22 [02:19<02:19, 12.67s/it]\u001b[A\n",
      "Epoch 9/10:  55%|█████▍    | 12/22 [02:31<02:03, 12.35s/it]\u001b[A\n",
      "Epoch 9/10:  59%|█████▉    | 13/22 [02:44<01:54, 12.69s/it]\u001b[A\n",
      "Epoch 9/10:  64%|██████▎   | 14/22 [02:59<01:46, 13.26s/it]\u001b[A\n",
      "Epoch 9/10:  68%|██████▊   | 15/22 [03:14<01:35, 13.71s/it]\u001b[A\n",
      "Epoch 9/10:  73%|███████▎  | 16/22 [03:25<01:17, 12.91s/it]\u001b[A\n",
      "Epoch 9/10:  77%|███████▋  | 17/22 [03:36<01:03, 12.61s/it]\u001b[A\n",
      "Epoch 9/10:  82%|████████▏ | 18/22 [03:47<00:48, 12.12s/it]\u001b[A\n",
      "Epoch 9/10:  86%|████████▋ | 19/22 [03:59<00:35, 11.86s/it]\u001b[A\n",
      "Epoch 9/10:  91%|█████████ | 20/22 [04:09<00:22, 11.48s/it]\u001b[A\n",
      "Epoch 9/10:  95%|█████████▌| 21/22 [04:22<00:11, 11.86s/it]\u001b[A\n",
      "Epoch 9/10: 100%|██████████| 22/22 [04:35<00:00, 12.06s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [45:03<05:00, 300.51s/it]            \u001b[A\n",
      "Epoch 10/10:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10/10:   5%|▍         | 1/22 [00:10<03:49, 10.94s/it]\u001b[A\n",
      "Epoch 10/10:   9%|▉         | 2/22 [00:23<04:01, 12.10s/it]\u001b[A\n",
      "Epoch 10/10:  14%|█▎        | 3/22 [00:38<04:13, 13.37s/it]\u001b[A\n",
      "Epoch 10/10:  18%|█▊        | 4/22 [00:50<03:46, 12.58s/it]\u001b[A\n",
      "Epoch 10/10:  23%|██▎       | 5/22 [01:04<03:42, 13.08s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# Set up the study\n",
    "study_name = 'astrid_gnn_optimization'\n",
    "n_trials = 50  # Total number of trials to run (including previous ones if resuming)\n",
    "n_jobs = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the directory for saving files\n",
    "save_dir = '/scratch/gpfs/hk4638/astrid_optimization/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Set up the storage\n",
    "storage_name = os.path.join(save_dir, 'astrid_study.db')\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=f\"sqlite:///{storage_name}\",\n",
    "    engine_kwargs={\"connect_args\": {\"timeout\": 100}}\n",
    ")\n",
    "\n",
    "# Check if the study already exists\n",
    "try:\n",
    "    study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "    print(f\"Resuming optimization from existing study '{study_name}'\")\n",
    "    print(f\"Number of completed trials: {len(study.trials)}\")\n",
    "except KeyError:\n",
    "    # If the study doesn't exist, create a new one\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage, \n",
    "                                sampler=optuna.samplers.TPESampler(n_startup_trials=10),\n",
    "                                direction='minimize')\n",
    "    print(f\"Created new study '{study_name}'\")\n",
    "\n",
    "# Create the objective\n",
    "objective = Objective(num_features=normalized_data_list[0].num_node_features, device=device, epochs=10, \n",
    "                      train_loader=train_loader, val_loader=val_loader)\n",
    "\n",
    "# Calculate the number of trials to run\n",
    "n_trials_to_run = max(0, n_trials - len(study.trials))\n",
    "\n",
    "if n_trials_to_run > 0:\n",
    "    print(f\"Running {n_trials_to_run} additional trials...\")\n",
    "    study.optimize(objective, n_trials=n_trials_to_run, n_jobs=n_jobs)\n",
    "else:\n",
    "    print(\"No additional trials to run. The study has already completed the specified number of trials.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "def reset_optuna_database(study_name, storage_path):\n",
    "    \"\"\"\n",
    "    Reset the Optuna database by deleting the existing file and creating a new study.\n",
    "    \n",
    "    Args:\n",
    "    study_name (str): The name of the study.\n",
    "    storage_path (str): The path to the SQLite database file.\n",
    "    \n",
    "    Returns:\n",
    "    optuna.Study: A new Optuna study object.\n",
    "    \"\"\"\n",
    "    # Check if the database file exists\n",
    "    if os.path.exists(storage_path):\n",
    "        # Confirm with the user before deleting\n",
    "        confirm = input(f\"Are you sure you want to delete the existing study '{study_name}'? (y/n): \")\n",
    "        if confirm.lower() == 'y':\n",
    "            # Delete the existing database file\n",
    "            os.remove(storage_path)\n",
    "            print(f\"Deleted existing database: {storage_path}\")\n",
    "        else:\n",
    "            print(\"Database reset cancelled.\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"Created new study '{study_name}' at {storage_path}\")\n",
    "    return study\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Are you sure you want to delete the existing study 'astrid_gnn_optimization'? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing database: /scratch/gpfs/hk4638/astrid_optimization/astrid_study.db\n",
      "Created new study 'astrid_gnn_optimization' at /scratch/gpfs/hk4638/astrid_optimization/astrid_study.db\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Set up the study\n",
    "study_name = 'astrid_gnn_optimization'\n",
    "storage_path = '/scratch/gpfs/hk4638/astrid_optimization/astrid_study.db'\n",
    "\n",
    "# Reset the database if desired\n",
    "study = reset_optuna_database(study_name, storage_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0jimGzhBHUd"
   },
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = normalized_data_list[0].num_node_features\n",
    "hidden_channels = 128\n",
    "num_layers = 3\n",
    "heads = 4\n",
    "dropout_rate = 0.4\n",
    "model = ComplexGAT(in_channels, hidden_channels, num_layers, heads, dropout_rate)\n",
    "model.load_state_dict(torch.load('/home/hk4638/ondemand/data/sys/AstridLH/best_model.pth'))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PJGIkgQzA-K8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.0047, Test R2: 0.6252\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "import matplotlib.pyplot as plt\n",
    "test_predictions, test_true = evaluate_model(trained_model, test_loader, device)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(test_true, test_predictions, alpha=0.5)\n",
    "plt.plot([min(test_true), max(test_true)], [min(test_true), max(test_true)], 'r--', lw=2)\n",
    "plt.xlabel('True $\\Omega_{m}$')\n",
    "plt.ylabel('Predicted $\\Omega_{m}$')\n",
    "plt.title('True vs Predicted $\\Omega_{m}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "astridenv [~/.conda/envs/astridenv/]",
   "language": "python",
   "name": "conda_astridenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

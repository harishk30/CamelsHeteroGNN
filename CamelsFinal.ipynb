{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep2eK29S_5qq"
   },
   "source": [
    "\n",
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90wz8D6UuSs9",
    "outputId": "dd983309-3b41-4363-eec7-483d11cfc237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.5.3\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JlLkEWbmiyYj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THXTiqZQmCO0"
   },
   "outputs": [],
   "source": [
    "M_star = f['Subhalo/SubhaloMassType'][:,4]*1e10\n",
    "pos  = f['Subhalo/SubhaloPos'][:]/1e3\n",
    "vel = f['Subhalo/SubhaloVel'][:]\n",
    "met = f['Subhalo/SubhaloStarMetallicity'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dgJ7wxu6sLUM"
   },
   "outputs": [],
   "source": [
    "def load_and_filter_data(file, mass_threshold=2e8):\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        positions = f['Subhalo/SubhaloPos'][:]/1e3  # Convert to Mpc/h\n",
    "        vel = f['Subhalo/SubhaloVel'][:]\n",
    "        metallicities = f['Subhalo/SubhaloStarMetallicity'][:]\n",
    "        masses = f['Subhalo/SubhaloMassType'][:,4]*1e10  # Stellar mass\n",
    "        omega_m = f['Header'].attrs['Omega0']\n",
    "\n",
    "    # Filter galaxies based on the stellar mass threshold\n",
    "    mask = masses > mass_threshold\n",
    "    positions = positions[mask]\n",
    "    vel = vel[mask]\n",
    "    metallicities = metallicities[mask]\n",
    "    masses = masses[mask]\n",
    "\n",
    "    return positions, vel, metallicities, masses, omega_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "--oaAn3kDLtU"
   },
   "outputs": [],
   "source": [
    "def apply_periodic_boundary_conditions(positions, box_size):\n",
    "    # Wrap positions to the box size\n",
    "    positions = positions % box_size\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B7VnGquYDPRe"
   },
   "outputs": [],
   "source": [
    "def minimum_image_distance(pos1, pos2, box_size):\n",
    "    # Calculate the minimum image distance between two points\n",
    "    delta = np.abs(pos1 - pos2)\n",
    "    delta = np.where(delta > 0.5 * box_size, box_size - delta, delta)\n",
    "    return np.sqrt((delta ** 2).sum(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lKOyScsvstrg"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def distance(point1, point2):\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def create_edges_knn(points, k=6):\n",
    "    edges = []\n",
    "    edge_value = []\n",
    "\n",
    "    # Create a KDTree for efficient nearest neighbor search\n",
    "    point_tree = KDTree(points)\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        # Query the k nearest neighbors for each point\n",
    "        _, neighbors = point_tree.query(points[i], k=k+1)\n",
    "\n",
    "        for j in neighbors[1:]:  # Skip the first neighbor because it's the point itself\n",
    "            # Add an edge between the point and its neighbor\n",
    "            edges.append([i, j])\n",
    "\n",
    "            # Compute the distance between the points as the edge value\n",
    "            edge_value.append(distance(points[i], points[j]))\n",
    "\n",
    "    return [edges, edge_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ztRfbIqROn7N"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def min_distance(positions, box_size = 25):\n",
    "    min_distance = np.inf\n",
    "    max_distance = 0\n",
    "\n",
    "    # Iterate over all pairs of galaxies\n",
    "    for i in range(len(positions)):\n",
    "        for j in range(i + 1, len(positions)):\n",
    "            dist = minimum_image_distance(positions[i], positions[j], box_size)\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Minimum distance: {min_distance} Mpc/h\")\n",
    "    print(f\"Maximum distance: {max_distance} Mpc/h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l40oy2_KRiWJ"
   },
   "outputs": [],
   "source": [
    "def minimum_image_distance_vectorized(positions, box_size = 25):\n",
    "    num_galaxies = positions.shape[0]\n",
    "\n",
    "    # Compute pairwise differences in each dimension\n",
    "    diff = positions[:, np.newaxis, :] - positions[np.newaxis, :, :]\n",
    "\n",
    "    # Apply periodic boundary conditions\n",
    "    diff = np.abs(diff)\n",
    "    diff = np.where(diff > 0.5 * box_size, box_size - diff, diff)\n",
    "\n",
    "    # Compute the Euclidean distance\n",
    "    dist = np.sqrt(np.sum(diff ** 2, axis=-1))\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zPQB3MDzDcid"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.spatial import cKDTree\n",
    "def create_edges_knn_pbc(points, box_size = 25, k=6):\n",
    "    tree = KDTree(points, boxsize=box_size)\n",
    "\n",
    "    edges = []\n",
    "    edge_values = []\n",
    "    '''\n",
    "    distances = minimum_image_distance_vectorized(points, box_size)\n",
    "    # Mask the diagonal (self-distances which are zero)\n",
    "    np.fill_diagonal(distances, np.inf)\n",
    "    # Get the minimum and maximum distances\n",
    "    min_distance = np.min(distances)\n",
    "    max_distance = np.max(np.triu(distances, k=1))\n",
    "    print(min_distance, max_distance)\n",
    "    '''\n",
    "\n",
    "    min_distance = np.inf\n",
    "    max_distance = 0\n",
    "    large_distance_count = 0\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        distances, neighbors = tree.query(points[i], k=k+1)\n",
    "        for j, tree_dist in zip(neighbors[1:], distances[1:]):\n",
    "            if j != i and j < len(points):\n",
    "                actual_distance = minimum_image_distance(points[i], points[j], box_size)\n",
    "                edges.append([i, j])\n",
    "                edge_values.append(actual_distance)\n",
    "                min_distance = min(min_distance, actual_distance)\n",
    "                max_distance = max(max_distance, actual_distance)\n",
    "    return np.array(edges), np.array(edge_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m5XiGu3wtkRA"
   },
   "outputs": [],
   "source": [
    "def create_points(positions, masses, vel, met):\n",
    "    point_features = []\n",
    "    for i, pos in enumerate(positions):\n",
    "        #point_features.append(list(pos) + list(vel[i]) + [masses[i]] + [met[i]])\n",
    "        point_features.append(list(pos) + [masses[i]] + [met[i]])\n",
    "    return point_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3CE9AtwhuAKs"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "def create_graph(file_path, k_val=6):\n",
    "    positions, velocity, metallicities, masses, omega_m = load_and_filter_data(file_path)\n",
    "    edges, edge_values = create_edges_knn_pbc(positions, 25, k_val)\n",
    "    point_values = create_points(positions, masses, velocity, metallicities)\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    point_values = torch.tensor(point_values, dtype=torch.float)\n",
    "    edge_value = torch.tensor(edge_values, dtype=torch.float)\n",
    "\n",
    "    return [point_values, edge_index, edge_value, omega_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mhxwN1mIub7M"
   },
   "outputs": [],
   "source": [
    "def turn_data(graph):\n",
    "    graph_data = Data(x=graph[0], edge_index=graph[1], edge_attr=graph[2], y = graph[3])\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_PXmi7cFLFqy"
   },
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "def create_data(file_path, k_val=6):\n",
    "    graph = create_graph(file_path, k_val)\n",
    "    data = turn_data(graph)\n",
    "    data = T.ToUndirected()(data)\n",
    "    #data = T.NormalizeFeatures()(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "V9zLYGSy_cz4"
   },
   "outputs": [],
   "source": [
    "def calculate_normalization_params(data_list):\n",
    "    # Concatenate all node features and edge attributes\n",
    "    all_x = torch.cat([data.x for data in data_list], dim=0)\n",
    "    all_edge_attr = torch.cat([data.edge_attr for data in data_list], dim=0)\n",
    "\n",
    "    # Calculate mean and std for node features and edge attributes\n",
    "    x_mean, x_std = all_x.mean(dim=0), all_x.std(dim=0)\n",
    "    edge_attr_mean, edge_attr_std = all_edge_attr.mean(dim=0), all_edge_attr.std(dim=0)\n",
    "\n",
    "    return (x_mean, x_std), (edge_attr_mean, edge_attr_std)\n",
    "\n",
    "def normalize_dataset(data_list, x_params, edge_attr_params):\n",
    "    x_mean, x_std = x_params\n",
    "    edge_attr_mean, edge_attr_std = edge_attr_params\n",
    "\n",
    "    normalized_data_list = []\n",
    "    for data in data_list:\n",
    "        normalized_x = (data.x - x_mean) / (x_std + 1e-8)\n",
    "        normalized_edge_attr = (data.edge_attr - edge_attr_mean) / (edge_attr_std + 1e-8)\n",
    "\n",
    "        # Create a new Data object with normalized features and original y value\n",
    "        normalized_data = Data(x=normalized_x,\n",
    "                               edge_index=data.edge_index,\n",
    "                               edge_attr=normalized_edge_attr,\n",
    "                               y=data.y)  # Preserve the original y value\n",
    "\n",
    "        normalized_data_list.append(normalized_data)\n",
    "\n",
    "    return normalized_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoAJQ_raMZ3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 903/1000 [03:03<00:20,  4.62it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "import h5py\n",
    "directory = '/scratch/gpfs/hk4638/FinalData/NewData'\n",
    "def load_all_graphs(directory, k_val=10, box_size=25):\n",
    "    file_list = os.listdir(directory)\n",
    "    data_list = []\n",
    "    for file_name in tqdm(file_list):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        graph_data = create_data(file_path, k_val)\n",
    "        data_list.append(graph_data)\n",
    "    return data_list\n",
    "\n",
    "# Load all graphs\n",
    "data_list = load_all_graphs(directory)\n",
    "\n",
    "# Calculate normalization parameters based on all graphs\n",
    "x_params, edge_attr_params = calculate_normalization_params(data_list)\n",
    "\n",
    "# Normalize the dataset using the calculated parameters\n",
    "normalized_data_list = normalize_dataset(data_list, x_params, edge_attr_params)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def numpy_to_torch_float(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return torch.from_numpy(data).float()\n",
    "    elif isinstance(data, (np.float64, np.float32)):\n",
    "        return torch.tensor(data, dtype=torch.float32)\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.float()\n",
    "    else:\n",
    "        return data\n",
    "        \n",
    "def ensure_torch_float32(data):\n",
    "    data.x = numpy_to_torch_float(data.x)\n",
    "    data.edge_attr = numpy_to_torch_float(data.edge_attr)\n",
    "    if hasattr(data, 'y'):\n",
    "        data.y = numpy_to_torch_float(data.y)\n",
    "    return data\n",
    "    \n",
    "normalized_data_list = [ensure_torch_float32(data) for data in normalized_data_list]\n",
    "\n",
    "# Calculate the lengths for the 70-15-15 split\n",
    "total_len = len(normalized_data_list)\n",
    "train_len = int(0.7 * total_len)\n",
    "val_len = int(0.15 * total_len)\n",
    "test_len = total_len - train_len - val_len  # Ensures all data is used\n",
    "\n",
    "# Perform the split\n",
    "train_data, val_data, test_data = random_split(normalized_data_list, [train_len, val_len, test_len])\n",
    "\n",
    "# Create DataLoaders for each split\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogenous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_and_filter_data(file, mass_threshold=2e8):\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        positions = f['Subhalo/SubhaloPos'][:]/1e3  # Convert to Mpc/h\n",
    "        metallicities = f['Subhalo/SubhaloStarMetallicity'][:]\n",
    "        masses = f['Subhalo/SubhaloMassType'][:,4]*1e10  # Stellar mass\n",
    "        omega_m = f['Header'].attrs['Omega0']\n",
    "    # Filter galaxies based on the stellar mass threshold\n",
    "    mask = masses > mass_threshold\n",
    "    return positions[mask], metallicities[mask], masses[mask], omega_m\n",
    "\n",
    "def split_galaxies(positions, masses, metallicities, split_ratios):\n",
    "    total_galaxies = len(positions)\n",
    "    indices = np.random.permutation(total_galaxies)\n",
    "    split_points = [int(ratio * total_galaxies) for ratio in np.cumsum(split_ratios)]\n",
    "    \n",
    "    a_indices = indices[:split_points[0]]\n",
    "    b_indices = indices[split_points[0]:split_points[1]]\n",
    "    c_indices = indices[split_points[1]:]\n",
    "    \n",
    "    return {\n",
    "        'A': (positions[a_indices], masses[a_indices], metallicities[a_indices]),\n",
    "        'B': (positions[b_indices], masses[b_indices], metallicities[b_indices]),\n",
    "        'C': (positions[c_indices], masses[c_indices], metallicities[c_indices])\n",
    "    }\n",
    "\n",
    "def minimum_image_distance(pos1, pos2, box_size):\n",
    "    delta = np.abs(pos1 - pos2)\n",
    "    delta = np.where(delta > 0.5 * box_size, box_size - delta, delta)\n",
    "    return np.sqrt((delta ** 2).sum(axis=-1))\n",
    "\n",
    "def create_edges_hetero(node_data, box_size=25, k=6):\n",
    "    all_positions = np.concatenate([node_data[t][0] for t in ['A', 'B', 'C']])\n",
    "    tree = cKDTree(all_positions, boxsize=box_size)\n",
    "    \n",
    "    edge_dict = {}\n",
    "    node_types = ['A', 'B', 'C']\n",
    "    start_idx = {'A': 0, 'B': len(node_data['A'][0]), 'C': len(node_data['A'][0]) + len(node_data['B'][0])}\n",
    "    \n",
    "    for src_type in node_types:\n",
    "        src_positions = node_data[src_type][0]\n",
    "        for dst_type in node_types:\n",
    "            dst_positions = node_data[dst_type][0]\n",
    "            edges = []\n",
    "            edge_attrs = []\n",
    "            \n",
    "            for i, pos in enumerate(src_positions):\n",
    "                distances, neighbors = tree.query(pos, k=k+1)\n",
    "                for j, dist in zip(neighbors[1:], distances[1:]):\n",
    "                    if start_idx[dst_type] <= j < start_idx[dst_type] + len(dst_positions):\n",
    "                        edges.append([i, j - start_idx[dst_type]])\n",
    "                        if src_type != 'B' and dst_type != 'B':\n",
    "                            actual_distance = minimum_image_distance(pos, all_positions[j], box_size)\n",
    "                            edge_attrs.append([actual_distance])\n",
    "                        else:\n",
    "                            edge_attrs.append([0.0])  # Placeholder for B connections\n",
    "            \n",
    "            if edges:\n",
    "                edge_dict[(src_type, 'to', dst_type)] = (np.array(edges).T, np.array(edge_attrs))\n",
    "    \n",
    "    return edge_dict\n",
    "\n",
    "def create_heterogeneous_graph(file_path, split_ratios, k_val=6):\n",
    "    positions, metallicities, masses, omega_m = load_and_filter_data(file_path)\n",
    "    node_data = split_galaxies(positions, masses, metallicities, split_ratios)\n",
    "    edge_dict = create_edges_hetero(node_data, k=k_val)\n",
    "    \n",
    "    data = HeteroData()\n",
    "    \n",
    "    # Add node features\n",
    "    data['A'].x = torch.tensor(np.column_stack(node_data['A'][0:1]), dtype=torch.float) # only position for A\n",
    "    data['B'].x = torch.tensor(np.column_stack(node_data['B'][1:]), dtype=torch.float)  # Exclude positions for B\n",
    "    data['C'].x = torch.tensor(np.column_stack(node_data['C']), dtype=torch.float)\n",
    "    \n",
    "    # Add edges\n",
    "    for edge_type, (edge_index, edge_attr) in edge_dict.items():\n",
    "        data[edge_type].edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        if edge_type[0] != 'B' and edge_type[2] != 'B':\n",
    "            data[edge_type].edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "    # Add global target\n",
    "    data.y = torch.tensor([omega_m], dtype=torch.float)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_dataset(file_paths, split_ratios, k_val=6):\n",
    "    dataset = []\n",
    "    for file_path in tqdm(file_paths, desc=\"Creating dataset\"):\n",
    "        graph = create_heterogeneous_graph(file_path, split_ratios, k_val)\n",
    "        graph = T.ToUndirected()(graph)\n",
    "        dataset.append(graph)\n",
    "    return dataset\n",
    "\n",
    "def calculate_normalization_params(dataset):\n",
    "    node_features = {node_type: [] for node_type in ['A', 'B', 'C']}\n",
    "    edge_features = {edge_type: [] for edge_type in [('A', 'to', 'A'), ('A', 'to', 'C'), ('C', 'to', 'C')]}\n",
    "    \n",
    "    for data in dataset:\n",
    "        for node_type in ['A', 'B', 'C']:\n",
    "            node_features[node_type].append(data[node_type].x)\n",
    "        \n",
    "        for edge_type in [('A', 'to', 'A'), ('A', 'to', 'C'), ('C', 'to', 'C')]:\n",
    "            if edge_type in data.edge_types and hasattr(data[edge_type], 'edge_attr'):\n",
    "                edge_features[edge_type].append(data[edge_type].edge_attr)\n",
    "    \n",
    "    norm_params = {}\n",
    "    for node_type, features in node_features.items():\n",
    "        if features:\n",
    "            features = torch.cat(features, dim=0)\n",
    "            norm_params[f'{node_type}_mean'] = features.mean(dim=0)\n",
    "            norm_params[f'{node_type}_std'] = features.std(dim=0)\n",
    "    \n",
    "    for edge_type, features in edge_features.items():\n",
    "        if features:\n",
    "            features = torch.cat(features, dim=0)\n",
    "            norm_params[f'{edge_type}_mean'] = features.mean(dim=0)\n",
    "            norm_params[f'{edge_type}_std'] = features.std(dim=0)\n",
    "    \n",
    "    return norm_params\n",
    "\n",
    "def normalize_graph(graph, norm_params):\n",
    "    for node_type in ['A', 'B', 'C']:\n",
    "        mean = norm_params[f'{node_type}_mean']\n",
    "        std = norm_params[f'{node_type}_std']\n",
    "        graph[node_type].x = (graph[node_type].x - mean) / (std + 1e-8)\n",
    "    \n",
    "    for edge_type in [('A', 'to', 'A'), ('A', 'to', 'C'), ('C', 'to', 'C')]:\n",
    "        if edge_type in graph.edge_types and hasattr(graph[edge_type], 'edge_attr'):\n",
    "            mean = norm_params[f'{edge_type}_mean']\n",
    "            std = norm_params[f'{edge_type}_std']\n",
    "            graph[edge_type].edge_attr = (graph[edge_type].edge_attr - mean) / (std + 1e-8)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def normalize_dataset(dataset):\n",
    "    norm_params = calculate_normalization_params(dataset)\n",
    "    normalized_dataset = [normalize_graph(graph, norm_params) for graph in dataset]\n",
    "    return normalized_dataset, norm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading graphs: 100%|██████████| 1000/1000 [02:11<00:00,  7.58it/s]\n",
      "/tmp/ipykernel_2029888/3858287339.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data[node_type].x = torch.tensor(data[node_type].x, dtype=torch.float32)\n",
      "/tmp/ipykernel_2029888/3858287339.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data[edge_type].edge_attr = torch.tensor(data[edge_type].edge_attr, dtype=torch.float32)\n",
      "/tmp/ipykernel_2029888/3858287339.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data.y = torch.tensor(data.y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs: 1000\n",
      "Number of training graphs: 700\n",
      "Number of validation graphs: 150\n",
      "Number of test graphs: 150\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming the previously defined functions are available:\n",
    "# create_heterogeneous_graph, calculate_normalization_params, normalize_graph\n",
    "\n",
    "directory = '/scratch/gpfs/hk4638/FinalData/NewData'\n",
    "\n",
    "def load_all_heterogeneous_graphs(directory, split_ratios, k_val=10, box_size=25):\n",
    "    file_list = os.listdir(directory)\n",
    "    data_list = []\n",
    "    for file_name in tqdm(file_list, desc=\"Loading graphs\"):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        graph_data = create_heterogeneous_graph(file_path, split_ratios, k_val)\n",
    "        data_list.append(graph_data)\n",
    "    return data_list\n",
    "\n",
    "# Load all heterogeneous graphs\n",
    "split_ratios = [0.3, 0.3, 0.4]  # 30% A, 30% B, 40% C\n",
    "data_list = load_all_heterogeneous_graphs(directory, split_ratios)\n",
    "\n",
    "# Calculate normalization parameters based on all graphs\n",
    "norm_params = calculate_normalization_params(data_list)\n",
    "\n",
    "# Normalize the dataset using the calculated parameters\n",
    "normalized_data_list = [normalize_graph(graph, norm_params) for graph in data_list]\n",
    "\n",
    "def ensure_torch_float32(data):\n",
    "    for node_type in data.node_types:\n",
    "        data[node_type].x = torch.tensor(data[node_type].x, dtype=torch.float32)\n",
    "    for edge_type in data.edge_types:\n",
    "        if hasattr(data[edge_type], 'edge_attr'):\n",
    "            data[edge_type].edge_attr = torch.tensor(data[edge_type].edge_attr, dtype=torch.float32)\n",
    "    data.y = torch.tensor(data.y, dtype=torch.float32)\n",
    "    return data\n",
    "\n",
    "normalized_data_list = [ensure_torch_float32(data) for data in normalized_data_list]\n",
    "\n",
    "# Calculate the lengths for the 70-15-15 split\n",
    "total_len = len(normalized_data_list)\n",
    "train_len = int(0.7 * total_len)\n",
    "val_len = int(0.15 * total_len)\n",
    "test_len = total_len - train_len - val_len  # Ensures all data is used\n",
    "\n",
    "# Perform the split\n",
    "train_data, val_data, test_data = random_split(normalized_data_list, [train_len, val_len, test_len])\n",
    "\n",
    "# Create DataLoaders for each split\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(f\"Total number of graphs: {total_len}\")\n",
    "print(f\"Number of training graphs: {train_len}\")\n",
    "print(f\"Number of validation graphs: {val_len}\")\n",
    "print(f\"Number of test graphs: {test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eD3eA9nTAAch"
   },
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, GATv2Conv, global_mean_pool\n",
    "\n",
    "class ComplexGAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers=4, heads=4, dropout_rate=0.1):\n",
    "        super(ComplexGAT, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads=heads, concat=True, edge_dim=1)\n",
    "        #self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, concat=True, edge_dim=1)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, edge_dim=1)\n",
    "            #GATConv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, edge_dim=1)\n",
    "            for _ in range(num_layers - 2)\n",
    "        ])\n",
    "\n",
    "        self.conv_last = GATv2Conv(hidden_channels * heads, hidden_channels, heads=1, concat=False, edge_dim=1)\n",
    "        #self.conv_last = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=False, edge_dim=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, 1)  # Output a single value for omega_m\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr=edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index, edge_attr=edge_attr))\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        x = self.conv_last(x, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mksges42ACLq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, GATv2Conv, global_mean_pool\n",
    "\n",
    "class ComplexGAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers=4, heads=4, dropout_rate=0.1):\n",
    "        super(ComplexGAT, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # First GAT layer\n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads=heads, concat=True, edge_dim=1)\n",
    "        self.ln1 = nn.LayerNorm(hidden_channels * heads)  # LayerNorm after first layer\n",
    "\n",
    "        # Intermediate GAT layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, edge_dim=1)\n",
    "            for _ in range(num_layers - 2)\n",
    "        ])\n",
    "        self.lns = nn.ModuleList([nn.LayerNorm(hidden_channels * heads) for _ in range(num_layers - 2)])\n",
    "\n",
    "        # Final GAT layer\n",
    "        self.conv_last = GATv2Conv(hidden_channels * heads, hidden_channels, heads=1, concat=False, edge_dim=1)\n",
    "        self.ln_last = nn.LayerNorm(hidden_channels)  # LayerNorm after last layer\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, 1)  # Output a single value for omega_m\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        # First GAT layer with LayerNorm\n",
    "        x = self.conv1(x, edge_index, edge_attr=edge_attr)\n",
    "        x = self.ln1(x)  # Apply LayerNorm\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        # Intermediate GAT layers with LayerNorm\n",
    "        for conv, ln in zip(self.convs, self.lns):\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            x = ln(x)  # Apply LayerNorm\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        # Final GAT layer with LayerNorm\n",
    "        x = self.conv_last(x, edge_index, edge_attr=edge_attr)\n",
    "        x = self.ln_last(x)  # Apply LayerNorm\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_scatter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_scatter\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_scatter'"
     ]
    }
   ],
   "source": [
    "import torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MetaLayer, global_add_pool, global_mean_pool, global_max_pool\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "class EdgeModel(nn.Module):\n",
    "    def __init__(self, node_in, edge_in, hidden_channels, edge_out):\n",
    "        super().__init__()\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(node_in*2 + edge_in, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, edge_out),\n",
    "            nn.LayerNorm(edge_out)\n",
    "        )\n",
    "        self.residual_proj = nn.Linear(edge_in, edge_out) if edge_in != edge_out else nn.Identity()\n",
    "\n",
    "    def forward(self, src, dest, edge_attr, u, batch):\n",
    "        out = torch.cat([src, dest, edge_attr], dim=1)\n",
    "        out = self.edge_mlp(out)\n",
    "        out = out + self.residual_proj(edge_attr)\n",
    "        return out\n",
    "\n",
    "class NodeModel(nn.Module):\n",
    "    def __init__(self, node_in, edge_in, hidden_channels, node_out):\n",
    "        super().__init__()\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(node_in + edge_in*3, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, node_out),\n",
    "            nn.LayerNorm(node_out)\n",
    "        )\n",
    "        self.residual_proj = nn.Linear(node_in, node_out) if node_in != node_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        row, col = edge_index\n",
    "        \n",
    "        out1 = torch.zeros(x.size(0), edge_attr.size(1), device=x.device).index_add_(0, col, edge_attr)\n",
    "        out2 = torch.zeros(x.size(0), edge_attr.size(1), device=x.device).index_add_(0, col, edge_attr)\n",
    "        out2 = torch.max(out2, out1)\n",
    "        out3 = out1 / (torch.zeros(x.size(0), 1, device=x.device).index_add_(0, col, torch.ones_like(edge_attr[:, :1])) + 1e-8)\n",
    "        \n",
    "        out = torch.cat([x, out1, out2, out3], dim=1)\n",
    "        out = self.node_mlp(out)\n",
    "        out = out + self.residual_proj(x)\n",
    "        return out\n",
    "\n",
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self, node_in, edge_in, hidden_channels, global_out):\n",
    "        super().__init__()\n",
    "        self.global_mlp = nn.Sequential(\n",
    "            nn.Linear(node_in + edge_in + 1, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, global_out),\n",
    "            nn.LayerNorm(global_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        row, col = edge_index\n",
    "        out = torch.cat([\n",
    "            global_mean_pool(x, batch),\n",
    "            global_mean_pool(edge_attr, batch[row]),\n",
    "            u\n",
    "        ], dim=1)\n",
    "        return self.global_mlp(out)\n",
    "\n",
    "class MetaLayerGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=1, num_layers=4, dropout_rate=0.1):\n",
    "        super(MetaLayerGNN, self).__init__()\n",
    "        \n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(in_channels, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels)\n",
    "        )\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(1, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels)\n",
    "        )\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            edge_model = EdgeModel(hidden_channels, hidden_channels, hidden_channels, hidden_channels)\n",
    "            node_model = NodeModel(hidden_channels, hidden_channels, hidden_channels, hidden_channels)\n",
    "            global_model = GlobalModel(hidden_channels, hidden_channels, hidden_channels, 1)\n",
    "            self.layers.append(MetaLayer(edge_model, node_model, global_model))\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_channels * 3 + 1, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.LayerNorm(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        u = torch.zeros(batch.max().item() + 1, 1, device=x.device)\n",
    "\n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr.unsqueeze(1))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x, edge_attr, u = checkpoint(layer, x, edge_index, edge_attr, u, batch)\n",
    "            x = F.relu(x)\n",
    "            edge_attr = F.relu(edge_attr)\n",
    "\n",
    "        add_pool = global_add_pool(x, batch)\n",
    "        mean_pool = global_mean_pool(x, batch)\n",
    "        max_pool = global_max_pool(x, batch)\n",
    "\n",
    "        out = torch.cat([add_pool, mean_pool, max_pool, u], dim=1)\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import HeteroConv, GATConv, SAGEConv, global_mean_pool\n",
    "\n",
    "class HeteroComplexGAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels_dict, hidden_channels, num_layers=4, heads=4, dropout_rate=0.1):\n",
    "        super(HeteroComplexGAT, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Input to same dimentions\n",
    "        self.lin_dict = nn.ModuleDict({\n",
    "            node_type: nn.Linear(in_channels_dict[node_type], hidden_channels * heads)\n",
    "            for node_type in in_channels_dict\n",
    "        })\n",
    "\n",
    "        \n",
    "        edge_types = [\n",
    "            ('A', 'to', 'A'), ('A', 'to', 'C'), ('C', 'to', 'A'), ('B', 'to', 'B'), ('B', 'to', 'C'), ('C', 'to', 'B'), ('C', 'to', 'C')\n",
    "        ]\n",
    "\n",
    "        # Initialize the first layer using HeteroConv with GATConv or SAGEConv depending on edge types\n",
    "        self.conv1 = HeteroConv({\n",
    "            edge_type: (GATConv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, add_self_loops=False, edge_dim=1) \n",
    "                        if edge_type[0] != 'B' and edge_type[2] != 'B' \n",
    "                        else SAGEConv(hidden_channels * heads, hidden_channels * heads))\n",
    "            for edge_type in edge_types\n",
    "        })\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers - 2):\n",
    "            conv = HeteroConv({\n",
    "                edge_type: (GATConv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, add_self_loops=False, edge_dim=1)\n",
    "                            if edge_type[0] != 'B' and edge_type[2] != 'B'\n",
    "                            else SAGEConv(hidden_channels * heads, hidden_channels * heads))\n",
    "                for edge_type in edge_types\n",
    "            })\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.conv_last = HeteroConv({\n",
    "            edge_type: (GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=False, add_self_loops=False, edge_dim=1)\n",
    "                        if edge_type[0] != 'B' and edge_type[2] != 'B'\n",
    "                        else SAGEConv(hidden_channels * heads, hidden_channels))\n",
    "            for edge_type in edge_types\n",
    "        })\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_channels * len(in_channels_dict), hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, 1)  # Output a single value for omega_m\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict, edge_index_dict, edge_attr_dict = data.x_dict, data.edge_index_dict, data.edge_attr_dict\n",
    "\n",
    "        # Apply initial linear transformation to standardize input dimensions\n",
    "        x_dict = {key: self.lin_dict[key](x) for key, x in x_dict.items()}\n",
    "\n",
    "        # Apply convolutional layers\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = {key: nn.functional.relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: nn.functional.dropout(x, p=self.dropout_rate, training=self.training) for key, x in x_dict.items()}\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict, edge_attr_dict)\n",
    "            x_dict = {key: nn.functional.relu(x) for key, x in x_dict.items()}\n",
    "            x_dict = {key: nn.functional.dropout(x, p=self.dropout_rate, training=self.training) for key, x in x_dict.items()}\n",
    "\n",
    "        x_dict = self.conv_last(x_dict, edge_index_dict, edge_attr_dict)\n",
    "\n",
    "        # Global mean pooling\n",
    "        x = torch.cat([global_mean_pool(x, data[node_type].batch) for node_type, x in x_dict.items()], dim=1)\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "_5UGNXhNAggG"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, num_epochs=100, load_best_model=False):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if load_best_model:\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('/scratch/gpfs/hk4638/astrid_optimization/model_54.pth'))\n",
    "            print(\"Loaded model from best_model.pth\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"best_model.pth not found. Starting with a new model.\")\n",
    "    lear_r = 0.01\n",
    "    #lear_r = 0.0008\n",
    "    #lear_r = 0.0008\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lear_r)  # Start with the highest learning rate\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    # Define a learning rate scheduler that adjusts the learning rate based on epoch\n",
    "    '''scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: \n",
    "                                            0.01 if epoch < 75 else\n",
    "                                            0.002 if epoch < 150 else\n",
    "                                            0.0004 if epoch < 225 else\n",
    "                                            0.00008)'''\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_mses = []\n",
    "    val_r2s = []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            epoch_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            for data in epoch_pbar:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = criterion(out, data.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                epoch_pbar.set_postfix({'Train Loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            # Step the scheduler to potentially adjust the learning rate\n",
    "            #scheduler.step()\n",
    "            \n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_predictions = []\n",
    "            val_true = []\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    data = data.to(device)\n",
    "                    out = model(data)\n",
    "                    val_loss += criterion(out, data.y).item()\n",
    "                    val_predictions.extend(out.cpu().numpy())\n",
    "                    val_true.extend(data.y.cpu().numpy())\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            val_mse = mean_squared_error(val_true, val_predictions)\n",
    "            val_r2 = r2_score(val_true, val_predictions)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            val_mses.append(val_mse)\n",
    "            val_r2s.append(val_r2)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "            print(f'  Train Loss: {train_loss:.4f}')\n",
    "            print(f'  Val Loss: {val_loss:.4f}')\n",
    "            print(f'  Val MSE: {val_mse:.4f}')\n",
    "            print(f'  Val R2: {val_r2:.4f}')\n",
    "            \n",
    "            # Save the model after each epoch\n",
    "            torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
    "            print(f'  Model saved as model_epoch_{epoch+1}.pth')\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model.state_dict()\n",
    "                torch.save(best_model, 'best_model.pth')\n",
    "                print('  New best model saved as best_model.pth!')\n",
    "            \n",
    "            print()  # Add an empty line for better readability between epochs\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted. Saving current model state...\")\n",
    "        torch.save(model.state_dict(), 'interrupted_model.pth')\n",
    "        print(\"Model saved as interrupted_model.pth\")\n",
    "        if best_model is not None:\n",
    "            model.load_state_dict(best_model)\n",
    "        return model, train_losses, val_losses, val_mses, val_r2s\n",
    "    \n",
    "    # Load the best model if training completed without interruption\n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "    \n",
    "    return model, train_losses, val_losses, val_mses, val_r2s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "5mxL3nt4Avrt",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: 100%|██████████| 22/22 [00:03<00:00,  5.65it/s, Train Loss=0.0275]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000:\n",
      "  Train Loss: 0.1666\n",
      "  Val Loss: 0.0122\n",
      "  Val MSE: 0.0124\n",
      "  Val R2: -0.0820\n",
      "  Model saved as model_epoch_1.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 2/1000: 100%|██████████| 22/22 [00:03<00:00,  5.77it/s, Train Loss=0.0124]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000:\n",
      "  Train Loss: 0.0198\n",
      "  Val Loss: 0.0114\n",
      "  Val MSE: 0.0114\n",
      "  Val R2: 0.0001\n",
      "  Model saved as model_epoch_2.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 3/1000: 100%|██████████| 22/22 [00:03<00:00,  5.77it/s, Train Loss=0.0217]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000:\n",
      "  Train Loss: 0.0172\n",
      "  Val Loss: 0.0115\n",
      "  Val MSE: 0.0115\n",
      "  Val R2: -0.0049\n",
      "  Model saved as model_epoch_3.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 4/1000: 100%|██████████| 22/22 [00:03<00:00,  5.79it/s, Train Loss=0.0141]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000:\n",
      "  Train Loss: 0.0155\n",
      "  Val Loss: 0.0115\n",
      "  Val MSE: 0.0115\n",
      "  Val R2: -0.0035\n",
      "  Model saved as model_epoch_4.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 5/1000: 100%|██████████| 22/22 [00:03<00:00,  5.82it/s, Train Loss=0.0135]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000:\n",
      "  Train Loss: 0.0152\n",
      "  Val Loss: 0.0114\n",
      "  Val MSE: 0.0114\n",
      "  Val R2: -0.0007\n",
      "  Model saved as model_epoch_5.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 6/1000: 100%|██████████| 22/22 [00:03<00:00,  5.77it/s, Train Loss=0.0160]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000:\n",
      "  Train Loss: 0.0157\n",
      "  Val Loss: 0.0119\n",
      "  Val MSE: 0.0120\n",
      "  Val R2: -0.0516\n",
      "  Model saved as model_epoch_6.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 7/1000: 100%|██████████| 22/22 [00:03<00:00,  5.83it/s, Train Loss=0.0138]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000:\n",
      "  Train Loss: 0.0158\n",
      "  Val Loss: 0.0126\n",
      "  Val MSE: 0.0125\n",
      "  Val R2: -0.0946\n",
      "  Model saved as model_epoch_7.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 8/1000: 100%|██████████| 22/22 [00:03<00:00,  5.75it/s, Train Loss=0.0155]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000:\n",
      "  Train Loss: 0.0154\n",
      "  Val Loss: 0.0118\n",
      "  Val MSE: 0.0119\n",
      "  Val R2: -0.0385\n",
      "  Model saved as model_epoch_8.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 9/1000: 100%|██████████| 22/22 [00:03<00:00,  5.69it/s, Train Loss=0.0122]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000:\n",
      "  Train Loss: 0.0155\n",
      "  Val Loss: 0.0115\n",
      "  Val MSE: 0.0116\n",
      "  Val R2: -0.0128\n",
      "  Model saved as model_epoch_9.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 10/1000: 100%|██████████| 22/22 [00:03<00:00,  5.77it/s, Train Loss=0.0131]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000:\n",
      "  Train Loss: 0.0152\n",
      "  Val Loss: 0.0116\n",
      "  Val MSE: 0.0116\n",
      "  Val R2: -0.0186\n",
      "  Model saved as model_epoch_10.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 11/1000: 100%|██████████| 22/22 [00:03<00:00,  5.72it/s, Train Loss=0.0205]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000:\n",
      "  Train Loss: 0.0151\n",
      "  Val Loss: 0.0122\n",
      "  Val MSE: 0.0122\n",
      "  Val R2: -0.0647\n",
      "  Model saved as model_epoch_11.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 12/1000: 100%|██████████| 22/22 [00:03<00:00,  5.76it/s, Train Loss=0.0148]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000:\n",
      "  Train Loss: 0.0151\n",
      "  Val Loss: 0.0115\n",
      "  Val MSE: 0.0115\n",
      "  Val R2: -0.0034\n",
      "  Model saved as model_epoch_12.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 13/1000: 100%|██████████| 22/22 [00:03<00:00,  5.75it/s, Train Loss=0.0179]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000:\n",
      "  Train Loss: 0.0151\n",
      "  Val Loss: 0.0125\n",
      "  Val MSE: 0.0125\n",
      "  Val R2: -0.0900\n",
      "  Model saved as model_epoch_13.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 14/1000: 100%|██████████| 22/22 [00:03<00:00,  5.76it/s, Train Loss=0.0136]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000:\n",
      "  Train Loss: 0.0158\n",
      "  Val Loss: 0.0118\n",
      "  Val MSE: 0.0118\n",
      "  Val R2: -0.0341\n",
      "  Model saved as model_epoch_14.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 15/1000: 100%|██████████| 22/22 [00:03<00:00,  5.75it/s, Train Loss=0.0178]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000:\n",
      "  Train Loss: 0.0151\n",
      "  Val Loss: 0.0111\n",
      "  Val MSE: 0.0112\n",
      "  Val R2: 0.0235\n",
      "  Model saved as model_epoch_15.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 16/1000: 100%|██████████| 22/22 [00:03<00:00,  5.77it/s, Train Loss=0.0179]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000:\n",
      "  Train Loss: 0.0148\n",
      "  Val Loss: 0.0124\n",
      "  Val MSE: 0.0124\n",
      "  Val R2: -0.0809\n",
      "  Model saved as model_epoch_16.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 17/1000: 100%|██████████| 22/22 [00:03<00:00,  5.74it/s, Train Loss=0.0119]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000:\n",
      "  Train Loss: 0.0142\n",
      "  Val Loss: 0.0108\n",
      "  Val MSE: 0.0109\n",
      "  Val R2: 0.0449\n",
      "  Model saved as model_epoch_17.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 18/1000: 100%|██████████| 22/22 [00:03<00:00,  5.75it/s, Train Loss=0.0120]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000:\n",
      "  Train Loss: 0.0138\n",
      "  Val Loss: 0.0153\n",
      "  Val MSE: 0.0156\n",
      "  Val R2: -0.3608\n",
      "  Model saved as model_epoch_18.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 19/1000: 100%|██████████| 22/22 [00:03<00:00,  5.62it/s, Train Loss=0.0123]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000:\n",
      "  Train Loss: 0.0163\n",
      "  Val Loss: 0.0124\n",
      "  Val MSE: 0.0123\n",
      "  Val R2: -0.0772\n",
      "  Model saved as model_epoch_19.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 20/1000: 100%|██████████| 22/22 [00:03<00:00,  5.81it/s, Train Loss=0.0162]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000:\n",
      "  Train Loss: 0.0142\n",
      "  Val Loss: 0.0109\n",
      "  Val MSE: 0.0110\n",
      "  Val R2: 0.0389\n",
      "  Model saved as model_epoch_20.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 21/1000: 100%|██████████| 22/22 [00:03<00:00,  5.72it/s, Train Loss=0.0159]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000:\n",
      "  Train Loss: 0.0145\n",
      "  Val Loss: 0.0110\n",
      "  Val MSE: 0.0110\n",
      "  Val R2: 0.0369\n",
      "  Model saved as model_epoch_21.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 22/1000: 100%|██████████| 22/22 [00:03<00:00,  5.73it/s, Train Loss=0.0169]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000:\n",
      "  Train Loss: 0.0147\n",
      "  Val Loss: 0.0111\n",
      "  Val MSE: 0.0111\n",
      "  Val R2: 0.0318\n",
      "  Model saved as model_epoch_22.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 23/1000: 100%|██████████| 22/22 [00:03<00:00,  5.77it/s, Train Loss=0.0160]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000:\n",
      "  Train Loss: 0.0137\n",
      "  Val Loss: 0.0116\n",
      "  Val MSE: 0.0116\n",
      "  Val R2: -0.0163\n",
      "  Model saved as model_epoch_23.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 24/1000: 100%|██████████| 22/22 [00:03<00:00,  5.77it/s, Train Loss=0.0147]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000:\n",
      "  Train Loss: 0.0147\n",
      "  Val Loss: 0.0113\n",
      "  Val MSE: 0.0113\n",
      "  Val R2: 0.0083\n",
      "  Model saved as model_epoch_24.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 25/1000: 100%|██████████| 22/22 [00:03<00:00,  5.73it/s, Train Loss=0.0155]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000:\n",
      "  Train Loss: 0.0136\n",
      "  Val Loss: 0.0111\n",
      "  Val MSE: 0.0112\n",
      "  Val R2: 0.0217\n",
      "  Model saved as model_epoch_25.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 26/1000: 100%|██████████| 22/22 [00:03<00:00,  5.71it/s, Train Loss=0.0168]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000:\n",
      "  Train Loss: 0.0136\n",
      "  Val Loss: 0.0102\n",
      "  Val MSE: 0.0103\n",
      "  Val R2: 0.1017\n",
      "  Model saved as model_epoch_26.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 27/1000: 100%|██████████| 22/22 [00:03<00:00,  5.73it/s, Train Loss=0.0110]\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000:\n",
      "  Train Loss: 0.0135\n",
      "  Val Loss: 0.0114\n",
      "  Val MSE: 0.0114\n",
      "  Val R2: 0.0021\n",
      "  Model saved as model_epoch_27.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000:   0%|          | 0/22 [00:00<?, ?it/s]/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/hk4638/.conda/envs/com/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 28/1000:  91%|█████████ | 20/22 [00:03<00:00,  5.57it/s, Train Loss=0.0119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training interrupted. Saving current model state...\n",
      "Model saved as interrupted_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize model\n",
    "in_channels = normalized_data_list[0].num_node_features\n",
    "hidden_channels = 64\n",
    "out_channels = 1  # Assuming you're predicting a single value\n",
    "num_layers = 3\n",
    "heads = 16\n",
    "dropout_rate = 0.16841713216269857\n",
    "residuals = True\n",
    "\n",
    "model = MetaLayerGNN(\n",
    "    in_channels=in_channels, \n",
    "    hidden_channels=hidden_channels, \n",
    "    out_channels=out_channels, \n",
    "    num_layers=num_layers, \n",
    "    dropout_rate=dropout_rate\n",
    ")\n",
    "\n",
    "# Train model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = train_model(model, train_loader, val_loader, device, num_epochs=1000, load_best_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: 100%|██████████| 22/22 [02:42<00:00,  7.38s/it, Train Loss=0.2628]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000:\n",
      "  Train Loss: 3236.5800\n",
      "  Val Loss: 0.4463\n",
      "  Val MSE: 0.4362\n",
      "  Val R2: -32.1140\n",
      "  Model saved as model_epoch_1.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000: 100%|██████████| 22/22 [03:04<00:00,  8.38s/it, Train Loss=0.0535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000:\n",
      "  Train Loss: 0.1794\n",
      "  Val Loss: 0.1690\n",
      "  Val MSE: 0.1447\n",
      "  Val R2: -9.9839\n",
      "  Model saved as model_epoch_2.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000: 100%|██████████| 22/22 [03:02<00:00,  8.29s/it, Train Loss=0.0384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000:\n",
      "  Train Loss: 0.0685\n",
      "  Val Loss: 0.0255\n",
      "  Val MSE: 0.0257\n",
      "  Val R2: -0.9499\n",
      "  Model saved as model_epoch_3.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000: 100%|██████████| 22/22 [03:05<00:00,  8.43s/it, Train Loss=0.0264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000:\n",
      "  Train Loss: 0.0256\n",
      "  Val Loss: 0.0223\n",
      "  Val MSE: 0.0224\n",
      "  Val R2: -0.7039\n",
      "  Model saved as model_epoch_4.pth\n",
      "  New best model saved as best_model.pth!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000: 100%|██████████| 22/22 [03:04<00:00,  8.40s/it, Train Loss=0.0214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000:\n",
      "  Train Loss: 0.0276\n",
      "  Val Loss: 0.0757\n",
      "  Val MSE: 0.0765\n",
      "  Val R2: -4.8065\n",
      "  Model saved as model_epoch_5.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000:  50%|█████     | 11/22 [01:30<01:38,  8.96s/it, Train Loss=0.0340]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming normalized_data_list is a list of HeteroData objects\n",
    "# Define input channels for each node type (example: {'A': 16, 'B': 32, 'C': 64})\n",
    "# You'll need to replace these values with the actual number of features for each node type\n",
    "in_channels_dict = {\n",
    "    'A': normalized_data_list[0]['A'].num_node_features,\n",
    "    'B': normalized_data_list[0]['B'].num_node_features,\n",
    "    'C': normalized_data_list[0]['C'].num_node_features\n",
    "}\n",
    "\n",
    "# Initialize model with heterogeneous data\n",
    "hidden_channels = 64\n",
    "num_layers = 2\n",
    "heads = 16\n",
    "dropout_rate = 0.16841713216269857\n",
    "\n",
    "# Use the HeteroComplexGAT model instead of ComplexGAT\n",
    "model = HeteroComplexGAT(in_channels_dict, hidden_channels, num_layers, heads, dropout_rate)\n",
    "\n",
    "# Train model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming train_loader and val_loader are DataLoader objects for HeteroData\n",
    "trained_model = train_model(model, train_loader, val_loader, device, num_epochs=1000, load_best_model=False)\n",
    "\n",
    "# Optionally, plot the loss curve or evaluate the model further here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "import gc\n",
    "import json\n",
    "from tqdm import tqdm # Ensure this import is correct\n",
    "\n",
    "class Objective(object):\n",
    "    def __init__(self, num_features, device, epochs, train_loader, val_loader):\n",
    "        self.num_features = num_features\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.best_trial_number = None\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        save_dir = '/scratch/gpfs/hk4638/astrid_optimization'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        fout = os.path.join(save_dir, f'loss_{trial.number}.txt')\n",
    "        fmodel = os.path.join(save_dir, f'model_{trial.number}.pth')\n",
    "        fhyper = os.path.join(save_dir, f'hyperparameters_{trial.number}.json')\n",
    "\n",
    "        # Suggest hyperparameters for MetaLayerGNN\n",
    "        hidden_channels = trial.suggest_categorical('hidden_channels', [64, 128])\n",
    "        num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "        lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "\n",
    "        hyperparameters = {\n",
    "            'hidden_channels': hidden_channels,\n",
    "            'num_layers': num_layers,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'lr': lr\n",
    "        }\n",
    "        with open(fhyper, 'w') as f:\n",
    "            json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "        # Generate the model architecture\n",
    "        model = MetaLayerGNN(in_channels=self.num_features, \n",
    "                             hidden_channels=hidden_channels,\n",
    "                             out_channels=1,  # Assuming single output\n",
    "                             num_layers=num_layers, \n",
    "                             dropout_rate=dropout_rate).to(self.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "    \n",
    "        def train():\n",
    "            model.train()\n",
    "            train_bar = tqdm(self.train_loader, leave=False, desc=f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "            for data in train_bar:\n",
    "                data = data.to(self.device)\n",
    "                out = model(data)\n",
    "                loss = criterion(out.squeeze(), data.y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        def validate(loader):\n",
    "            model.eval()\n",
    "            total_loss = 0\n",
    "            num_batches = 0\n",
    "            with torch.no_grad():\n",
    "                for data in loader:\n",
    "                    data = data.to(self.device)\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out.squeeze(), data.y)\n",
    "                    total_loss += loss.item()\n",
    "                    num_batches += 1\n",
    "            return total_loss / num_batches\n",
    "\n",
    "        trial_best_val_loss = float('inf')\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            train()\n",
    "            val_loss = validate(self.val_loader)\n",
    "            \n",
    "            if val_loss < trial_best_val_loss:\n",
    "                trial_best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), fmodel)\n",
    "            \n",
    "            with open(fout, 'a') as f:\n",
    "                f.write(f'{epoch} {val_loss:.5e} {trial_best_val_loss:.5e}\\n')\n",
    "\n",
    "            trial.report(val_loss, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        if trial_best_val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = trial_best_val_loss\n",
    "            self.best_trial_number = trial.number\n",
    "\n",
    "            with open(os.path.join(save_dir, 'best_trial.json'), 'w') as f:\n",
    "                json.dump({\n",
    "                    'best_trial_number': self.best_trial_number,\n",
    "                    'best_val_loss': self.best_val_loss\n",
    "                }, f, indent=4)\n",
    "\n",
    "        print(f\"\\n--- Trial {trial.number} Results ---\")\n",
    "        print(\"Hyperparameters:\")\n",
    "        for key, value in trial.params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(f\"\\nCurrent Model Architecture:\\n{model}\")\n",
    "        print(f\"\\nBest Validation Loss for this trial: {trial_best_val_loss:.5e}\")\n",
    "        print(f\"Best Overall Validation Loss: {self.best_val_loss:.5e} (Trial {self.best_trial_number})\")\n",
    "\n",
    "        del model, optimizer, scheduler, criterion\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return trial_best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the study\n",
    "study_name = 'metaln'\n",
    "n_trials = 100  # Total number of trials to run (including previous ones if resuming)\n",
    "n_jobs = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the directory for saving files\n",
    "save_dir = '/scratch/gpfs/hk4638/astrid_optimization/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Set up the storage\n",
    "storage_name = os.path.join(save_dir, 'new_astrid_study.db')\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=f\"sqlite:///{storage_name}\",\n",
    "    engine_kwargs={\"connect_args\": {\"timeout\": 100}}\n",
    ")\n",
    "\n",
    "# Check if the study already exists\n",
    "try:\n",
    "    study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "    print(f\"Resuming optimization from existing study '{study_name}'\")\n",
    "    print(f\"Number of completed trials: {len(study.trials)}\")\n",
    "except KeyError:\n",
    "    # If the study doesn't exist, create a new one\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage, \n",
    "                                sampler=optuna.samplers.TPESampler(n_startup_trials=10),\n",
    "                                direction='minimize')\n",
    "    print(f\"Created new study '{study_name}'\")\n",
    "\n",
    "# Create the objective\n",
    "objective = Objective(num_features=normalized_data_list[0].num_node_features, epochs=50, device=device,\n",
    "                      train_loader = train_loader, val_loader = val_loader)\n",
    "\n",
    "# Calculate the number of trials to run\n",
    "n_trials_to_run = max(0, n_trials - len(study.trials))\n",
    "\n",
    "if n_trials_to_run > 0:\n",
    "    print(f\"Running {n_trials_to_run} additional trials...\")\n",
    "    study.optimize(objective, n_trials=n_trials_to_run, n_jobs=n_jobs)\n",
    "else:\n",
    "    print(\"No additional trials to run. The study has already completed the specified number of trials.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target trial number 8 is greater than or equal to the highest trial number (-1). No reset needed.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "def reset_study_to_trial(study_name, storage_path, target_trial_number):\n",
    "    if not os.path.exists(storage_path):\n",
    "        raise FileNotFoundError(f\"Database file not found: {storage_path}\")\n",
    "\n",
    "    storage_url = f\"sqlite:///{storage_path}\"\n",
    "    \n",
    "    # Load the existing study\n",
    "    old_study = optuna.load_study(study_name=study_name, storage=storage_url)\n",
    "    \n",
    "    # Get the total number of trials\n",
    "    total_trials = len(old_study.trials)\n",
    "    \n",
    "    if target_trial_number >= total_trials - 1:\n",
    "        print(f\"Target trial number {target_trial_number} is greater than or equal to the highest trial number ({total_trials - 1}). No reset needed.\")\n",
    "        return old_study\n",
    "    \n",
    "    # Confirm with the user\n",
    "    print(f\"This will reset the study to include only trials up to and including trial {target_trial_number}.\")\n",
    "    print(f\"Current number of trials: {total_trials}\")\n",
    "    print(f\"Number of trials to keep: {target_trial_number + 1}\")\n",
    "    print(f\"Number of trials to remove: {total_trials - (target_trial_number + 1)}\")\n",
    "    confirm = input(\"Are you sure you want to proceed? (yes/no): \")\n",
    "    \n",
    "    if confirm.lower() != 'yes':\n",
    "        print(\"Operation cancelled.\")\n",
    "        return old_study\n",
    "    \n",
    "    # Create a new study with the same name (this will overwrite the old one)\n",
    "    new_study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_url,\n",
    "        direction=old_study.direction,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    # Clear all trials from the new study\n",
    "    new_study._storage.delete_study(new_study._study_id)\n",
    "    \n",
    "    # Recreate the study\n",
    "    new_study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_url,\n",
    "        direction=old_study.direction,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    # Copy trials up to and including the target trial number\n",
    "    for trial in old_study.trials[:target_trial_number + 1]:\n",
    "        if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "            new_study.add_trial(\n",
    "                optuna.trial.create_trial(\n",
    "                    params=trial.params,\n",
    "                    distributions=trial.distributions,\n",
    "                    value=trial.value,\n",
    "                    state=trial.state\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    print(f\"Study reset to include {len(new_study.trials)} trials\")\n",
    "    return new_study\n",
    "\n",
    "# Usage\n",
    "storage_path = \"/scratch/gpfs/hk4638/astrid_optimization/astrid_study.db\"\n",
    "study_name = \"astrid_gnn_optimization\"\n",
    "target_trial_number = 8\n",
    "\n",
    "try:\n",
    "    study = reset_study_to_trial(study_name, storage_path, target_trial_number)\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please check the path to your database file and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    raise  # This will print the full traceback\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "def reset_optuna_database(study_name, storage_path):\n",
    "    \"\"\"\n",
    "    Reset the Optuna database by deleting the existing file and creating a new study.\n",
    "    \n",
    "    Args:\n",
    "    study_name (str): The name of the study.\n",
    "    storage_path (str): The path to the SQLite database file.\n",
    "    \n",
    "    Returns:\n",
    "    optuna.Study: A new Optuna study object.\n",
    "    \"\"\"\n",
    "    # Check if the database file exists\n",
    "    if os.path.exists(storage_path):\n",
    "        # Confirm with the user before deleting\n",
    "        confirm = input(f\"Are you sure you want to delete the existing study '{study_name}'? (y/n): \")\n",
    "        if confirm.lower() == 'y':\n",
    "            # Delete the existing database file\n",
    "            os.remove(storage_path)\n",
    "            print(f\"Deleted existing database: {storage_path}\")\n",
    "        else:\n",
    "            print(\"Database reset cancelled.\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"Created new study '{study_name}' at {storage_path}\")\n",
    "    return study\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Are you sure you want to delete the existing study 'astrid_gnn_optimization'? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing database: /scratch/gpfs/hk4638/astrid_optimization/astrid_study.db\n",
      "Created new study 'astrid_gnn_optimization' at /scratch/gpfs/hk4638/astrid_optimization/astrid_study.db\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Set up the study\n",
    "study_name = 'astrid_gnn_optimization'\n",
    "storage_path = '/scratch/gpfs/hk4638/astrid_optimization/astrid_study.db'\n",
    "\n",
    "# Reset the database if desired\n",
    "study = reset_optuna_database(study_name, storage_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0jimGzhBHUd"
   },
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = normalized_data_list[0].num_node_features\n",
    "hidden_channels = 64\n",
    "num_layers = 2\n",
    "heads = 16\n",
    "dropout_rate = 0.1\n",
    "model = ComplexGAT(in_channels, hidden_channels, num_layers, heads, dropout_rate)\n",
    "path = '/scratch/gpfs/hk4638/astrid_optimization/model_54.pth'\n",
    "model.load_state_dict(torch.load(path))\n",
    "device = torch.device('cuda')\n",
    "trained_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    test_predictions = []\n",
    "    test_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            test_predictions.append(out)\n",
    "            test_true.append(data.y.to(device))\n",
    "    \n",
    "    test_predictions = torch.cat(test_predictions, dim=0)\n",
    "    test_true = torch.cat(test_true, dim=0)\n",
    "    \n",
    "    # Move to CPU for metric computation\n",
    "    test_predictions_cpu = test_predictions.cpu().numpy()\n",
    "    test_true_cpu = test_true.cpu().numpy()\n",
    "    \n",
    "    # Calculate R² using sklearn (as a double-check)\n",
    "    r2_sklearn = r2_score(test_true_cpu, test_predictions_cpu)\n",
    "    \n",
    "    # Calculate R² using the provided formula\n",
    "    y_true_mean = np.mean(test_true_cpu)\n",
    "    numerator = np.sum((test_true_cpu - test_predictions_cpu)**2)\n",
    "    denominator = np.sum((test_true_cpu - y_true_mean)**2)\n",
    "    r2 = 1 - (numerator / denominator)\n",
    "    test_mse = mean_squared_error(test_true_cpu, test_predictions_cpu)\n",
    "    \n",
    "    # Calculate mean relative error (ε)\n",
    "    epsilon_small = 1e-8\n",
    "    epsilon = np.mean(np.abs(test_true_cpu - test_predictions_cpu) / (test_true_cpu + epsilon_small))\n",
    "\n",
    "    \n",
    "    print(f'R² (custom): {r2:.4f}')\n",
    "    print(f'R² (sklearn): {r2_sklearn:.4f}')\n",
    "    print(f'Mean Relative Error (ε): {epsilon:.4f}')\n",
    "    \n",
    "    return test_predictions_cpu, test_true_cpu, r2, epsilon, test_mse\n",
    "\n",
    "# Usage example:\n",
    "# predictions, true_values, r2, epsilon, chi_squared = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PJGIkgQzA-K8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² (custom): 0.7127\n",
      "R² (sklearn): 0.7127\n",
      "Mean Relative Error (ε): 0.1855\n",
      "0.004304029\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluate model\n",
    "test_predictions, test_true, r2, epsilon, test_mse = evaluate_model(trained_model, test_loader, device)\n",
    "\n",
    "print(test_mse)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(test_true, test_predictions, alpha=0.5)\n",
    "plt.plot([0, 0.5], [0, 0.5], color='red', linestyle='--')  # Perfect prediction line\n",
    "\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel(r'$\\Omega_m$')\n",
    "plt.title('Training in ASTRID, testing in ASTRID')\n",
    "\n",
    "# Add textbox with metrics\n",
    "textstr = '\\n'.join((\n",
    "    r'$\\Omega_m$',\n",
    "    r'$R^2=%.2f$' % (r2,),\n",
    "    r'$\\epsilon=%.1f\\%%$' % (epsilon*100,)\n",
    "))\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=9,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.text(0.75, 0.05, r'Positions + $M_*, Z_*$', transform=plt.gca().transAxes,\n",
    "         fontsize=9, verticalalignment='bottom', bbox=props)\n",
    "\n",
    "plt.xlim(0.1, 0.5)\n",
    "plt.ylim(0, 0.6)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "com [~/.conda/envs/com/]",
   "language": "python",
   "name": "conda_com"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
